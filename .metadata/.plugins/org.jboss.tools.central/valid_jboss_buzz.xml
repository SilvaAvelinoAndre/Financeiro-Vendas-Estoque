<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><entry><title>Tips for handling localized ranges in regular expressions</title><link rel="alternate" href="https://developers.redhat.com/blog/2020/12/22/what-to-do-about-rational-ranges-in-regular-expressions" /><author><name>Carlos O'Donell</name></author><id>6aac5134-349d-44f1-ba68-1d84eab780e0</id><updated>2023-04-06T07:00:00Z</updated><published>2023-04-06T07:00:00Z</published><summary type="html">&lt;p&gt;Developers as well as casual &lt;code&gt;grep&lt;/code&gt; users are accustomed to using ranges in &lt;a href="https://developers.redhat.com/articles/2022/09/14/beginners-guide-regular-expressions-grep"&gt;regular expressions&lt;/a&gt;, such as &lt;code&gt;[a-zA-Z]&lt;/code&gt; or &lt;code&gt;[0-9]&lt;/code&gt;. However, they often don't realize that these regular expressions harbor problems that can lead to unexpected behavior.&lt;/p&gt; &lt;p&gt;This article delves into the issues with using ranges in different locales and the solutions sought by developers of various libraries, including the GNU &lt;a href="https://developers.redhat.com/topics/c"&gt;C&lt;/a&gt; Library (glibc).&lt;/p&gt; &lt;h2&gt;The problem with regular expression ranges&lt;/h2&gt; &lt;p&gt;Under the &lt;a href="https://pubs.opengroup.org/onlinepubs/9699919799/xrat/V4_xbd_chap09.html"&gt;POSIX standard&lt;/a&gt;, a regular expression using a range expression has unspecified behavior in any locale other than the POSIX locale. This locale applies only to programs or environments whose environment variables for the locale (such as &lt;code&gt;LANG&lt;/code&gt; or &lt;code&gt;LC_ALL&lt;/code&gt;) specify either &lt;code&gt;POSIX&lt;/code&gt; or &lt;code&gt;C&lt;/code&gt;, or who don't have those environment variables set at all.&lt;/p&gt; &lt;p&gt;Of course, this hardly ever happens. Most people specify their country and language when setting up their system and get a locale such as &lt;code&gt;en_US.UTF-8&lt;/code&gt;, in this case, indicating U.S. English with UTF-8 characters.&lt;/p&gt; &lt;p&gt;For most programs and users, therefore, a popular regular expression range such as &lt;code&gt;[a-zA-Z]&lt;/code&gt; or &lt;code&gt;[0-9]&lt;/code&gt; has undefined and ultimately unreliable behavior. In theory, users should employ bracket expressions such as &lt;code&gt;[[:alpha:]]&lt;/code&gt; and &lt;code&gt;[[:digit:]]&lt;/code&gt;. In practice, it works as expected in many, but not all, locales.&lt;/p&gt; &lt;p&gt;What should a library do to support developers and make developing applications easier? We will explore current and upcoming solutions in the next sections.&lt;/p&gt; &lt;h2&gt;Possible solutions and their relationships to POSIX and Unicode&lt;/h2&gt; &lt;p&gt;There are a number of possible solutions. The support for ranges such as &lt;code&gt;[a-zA-Z]&lt;/code&gt; in the C (POSIX) locale is a clue that support for the ranges was implemented by early C libraries when ASCII was the norm. Although there are many conflicting solutions, each generally maps to one of the following implementations:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;strong&gt;Native character order (NCO):&lt;/strong&gt; This means that a developer looking at a code chart for the character set can logically identify all characters in the range by reviewing, in order, those characters in the code chart from the start of the range to the end of the range.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Collation element order (CEO):&lt;/strong&gt; This means that a developer looking at the locale sources for the current locale can logically identify all characters in the range by reviewing, in order, those characters in the &lt;a href="https://pubs.opengroup.org/onlinepubs/9699919799/basedefs/V1_chap07.html"&gt;&lt;code&gt;LC_COLLATE&lt;/code&gt;&lt;/a&gt; definition in the POSIX locale sources (later compiled into the binary locale on your system, e.g., &lt;code&gt;en_US.UTF-8&lt;/code&gt;) from the start of the range to the end of the range.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Collation sequence order (CSO):&lt;/strong&gt; This means that a developer looking at, for one definition of a natural language order, a dictionary with said natural language order can logically identify all characters in the range by reviewing, in order, those characters in the dictionary from the start of the range to the end of the range.&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;For example, in the article &lt;a href="https://www.boost.org/doc/libs/1_38_0/libs/regex/doc/html/boost_regex/syntax/basic_extended.html"&gt;Boost C++ POSIX regular extended expression APIs&lt;/a&gt;, the authors implemented CSO with an &lt;a href="https://www.boost.org/doc/libs/1_38_0/libs/regex/doc/html/boost_regex/ref/syntax_option_type/syntax_option_type_extended.html"&gt;option&lt;/a&gt; to fall back to NCO. As another example, the &lt;a href="https://www.gnu.org/software/gawk/manual/html_node/Regexp.html"&gt;GNU Awk (Gawk) implementation&lt;/a&gt; has two modes: a "traditional" mode that emulates NCO within certain ASCII ranges and a POSIX-based mode that emulates CSO. The Boost and Gawk implementations offer a very similar degree of choice between NCO and CSO.&lt;/p&gt; &lt;p&gt;In glibc, the implementation is based on the early POSIX specifications that required CEO. In the built-in C and POSIX locale, the NCO and CEO are equivalent because the ASCII character set order can be ordered the same as the collation elements in the locale source specification. The glibc locale for &lt;code&gt;en_US.UTF-8&lt;/code&gt; makes the NCO and CEO equivalent for lowercase Latin characters, uppercase Latin characters, and numbers in order to preserve developer expectations for sorting these ranges; e.g., lowercase Latin characters are not interleaved with uppercase Latin characters.&lt;/p&gt; &lt;p&gt;CEO and CSO require large element lists and thus add a lot more overhead to implementations than NCO.&lt;/p&gt; &lt;p&gt;The published &lt;a href="https://www.iso.org/standard/68309.html"&gt;ISO 14651 (2020) standard&lt;/a&gt;, most recently derived from Unicode 13.0.0 (2020), defines the international string ordering and comparison, and glibc uses this standard as the basis for string collation. The &lt;a href="https://unicode-org.github.io/icu/userguide/collation/"&gt;collation element ordering&lt;/a&gt; in the ISO standard interleaves lowercase and uppercase characters in such a way that CEO is more aligned to logical groups of letters e.g. A and a, instead of NCO. Direct usage of ISO 14651 in glibc &lt;a href="https://sourceware.org/bugzilla/show_bug.cgi?id=23393"&gt; caused regressions&lt;/a&gt; due to this grouping; e.g., &lt;code&gt;[a-z]&lt;/code&gt; would match &lt;code&gt;A&lt;/code&gt; unexpectedly.&lt;/p&gt; &lt;h2&gt;Current and upcoming solutions&lt;/h2&gt; &lt;p&gt;Boost's interface allows one to choose between a logical NCO or CSO (as defined for a single natural language ordering), thus offering two of three solutions listed in the previous section. A user who desires a distinct CEO can create a completely new locale source definition and distribute that to users that want a distinct ordering. Thread-safe locale APIs can be used to set and use the locale on a per-thread basis.&lt;/p&gt; &lt;p&gt;The APIs implemented by the ICU project support many possible CSOs for a given language, including dictionary sort, address book sort, calendar sort, etc. No single CSO will solve the needs of all users.&lt;/p&gt; &lt;p&gt;The glibc implementation of CEO does not meet the needs of developers who are either looking at a code chart or applying common-sense logic to natural language ordering. Migrating glibc from CEO to CSO seems like a logical way forward, but the internal implementation will need to be significantly improved to support this transition. The most straightforward first step is a &lt;a href="https://sourceware.org/bugzilla/show_bug.cgi?id=17318"&gt;C.UTF-8 that uses NCO in glibc&lt;/a&gt; and avoids the overhead of CEO or CSO.&lt;/p&gt; &lt;p&gt;With the release of glibc 2.35 in February 2022, the project now has an official harmonized and C.UTF-8 that will use NCO for ASCII regular expression ranges and NCO for collation (code-point collation order).&lt;/p&gt; &lt;p&gt;You can already use this new C.UTF-8 locale in Fedora (starting with Fedora 35).  In the future, C.UTF-8 will be &lt;a href="https://sourceware.org/bugzilla/show_bug.cgi?id=28255"&gt;extended to allow rational ranges that cover all code points in NCO&lt;/a&gt;.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/blog/2020/12/22/what-to-do-about-rational-ranges-in-regular-expressions" title="Tips for handling localized ranges in regular expressions"&gt;Tips for handling localized ranges in regular expressions&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Carlos O'Donell</dc:creator><dc:date>2023-04-06T07:00:00Z</dc:date></entry><entry><title>Kubernetes Patterns: The path to cloud native</title><link rel="alternate" href="https://developers.redhat.com/articles/2023/04/05/kubernetes-patterns-path-cloud-native" /><author><name>Bilgin Ibryam, Roland Huß</name></author><id>0efdb125-e706-4dac-8b88-8f29ededc4fd</id><updated>2023-04-05T07:00:00Z</updated><published>2023-04-05T07:00:00Z</published><summary type="html">&lt;p class="Indent1"&gt;&lt;strong&gt;Note: &lt;/strong&gt;The following is an excerpt from &lt;strong&gt;&lt;a href="https://developers.redhat.com/e-books/kubernetes-patterns-2nd-edition"&gt;Kubernetes Patterns, Second Edition&lt;/a&gt;&lt;/strong&gt;&lt;em&gt; &lt;/em&gt;by Bilgin Ibryam and Roland Huß (O'Reilly Media, March 2023). Download the e-book to learn how to solve common cloud native challenges with proven design patterns.&lt;/p&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/topics/microservices/"&gt;Microservices&lt;/a&gt; is among the most popular architectural styles for creating cloud native applications. They tackle software complexity through modularization of business capabilities and trading development complexity for operational complexity. That is why a key prerequisite for becoming successful with microservices is to create applications that can be operated at scale through &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;As part of the microservices movement, there is a tremendous amount of theory, techniques, and supplemental tools for creating microservices from scratch or for splitting monoliths into microservices. Most of these practices are based on &lt;a href="https://www.dddcommunity.org/book/evans_2003/"&gt;Domain-Driven Design&lt;/a&gt; by Eric Evans (Addison-Wesley) and the concepts of bounded contexts and aggregates. Bounded contexts deal with large models by dividing them into different components, and aggregates help to further group bounded contexts into modules with defined transaction boundaries. However, in addition to these business domain considerations, for each distributed system—whether it is based on microservices or not—there are also technical concerns around its external structure, and runtime coupling. &lt;a href="https://developers.redhat.com/topics/containers"&gt;Containers&lt;/a&gt; and container orchestrators such as Kubernetes bring in new primitives and abstractions to address the concerns of distributed applications, and here we discuss the various options to consider when putting a distributed system into Kubernetes.&lt;/p&gt; &lt;p&gt;Throughout this book, we look at container and platform interactions by treating the containers as black boxes. However, we created this section to emphasize the importance of what goes into containers. Containers and cloud native platforms bring tremendous benefits to your distributed applications, but if all you put into containers is rubbish, you will get distributed rubbish at scale. Figure 1-1 shows the mixture of the skills required for creating good cloud native applications and where Kubernetes patterns fit in.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/screenshot_2023-04-04_at_9.50.52_pm.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/screenshot_2023-04-04_at_9.50.52_pm.png?itok=EohnmTT_" width="600" height="591" alt="High-level text diagram depicting skills required for creating good cloud native applications, with clean code at the lowest level." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 1: The path to cloud native. Used with permission from Kubernetes Patterns, Second Edition by Bilgin Ibryam and Roland Huß (O’Reilly). Copyright 2023 Bilgin Ibryam and Roland Huß.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt;At a high level, creating good cloud native applications requires familiarity with multiple design techniques:&lt;/p&gt; &lt;ul&gt;&lt;li aria-level="1"&gt;At the lowest code level, every variable you define, every method you create, and every class you decide to instantiate plays a role in the long-term maintenance of the application. No matter what container technology and orchestration platform you use, the development team and the artifacts they create will have the most impact. It is important to grow developers who strive to write clean code, have the right number of automated tests, constantly refactor to improve code quality, and are guided by Software Craftsmanship principles at heart.&lt;/li&gt; &lt;li aria-level="1"&gt;Domain-driven design is about approaching software design from a business perspective with the intention of keeping the architecture as close to the real world as possible. This approach works best for object-oriented programming languages, but there are also other good ways to model and design software for real-world problems. A model with the right business and transaction boundaries, easy-to-consume interfaces, and rich APIs is the foundation for successful containerization and automation later.&lt;/li&gt; &lt;li aria-level="1"&gt;The hexagonal architecture and its variations, such as Onion and Clean architectures, improve the flexibility and maintainability of applications by decoupling the application components and providing standardized interfaces for interacting with them. By decoupling the core business logic of a system from the surrounding infrastructure, hexagonal architecture makes it easier to port the system to different environments or platforms. These architectures complement domain-driven design and help arrange application code with distinct boundaries and externalized infrastructure dependencies.&lt;/li&gt; &lt;li aria-level="1"&gt;The microservices architectural style and the twelve-factor app methodology very quickly evolved to become the norm for creating distributed applications and they provide valuable principles and practices for designing changing distributed applications. Applying these principles lets you create implementations that are optimized for scale, resiliency, and pace of change, which are common requirements for any modern software today.&lt;/li&gt; &lt;li aria-level="1"&gt;Containers were very quickly adopted as the standard way of packaging and running distributed applications, whether these are microservices or functions. Creating modular, reusable containers that are good cloud native citizens is another fundamental prerequisite. Cloud native is a term used to describe principles, patterns, and tools to automate containerized applications at scale. We use cloud native interchangeably with Kubernetes, which is the most popular open source cloud native platform available today.&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;In this book, we are not covering clean code, domain-driven design, hexagonal architecture, or microservices. We are focusing only on the patterns and practices addressing the concerns of the container orchestration. But for these patterns to be effective, your application needs to be designed well from the inside by using clean code practices, domain-driven design, hexagonal architecture-like isolation of external dependencies, microservices principles, and other relevant design techniques.&lt;/p&gt; &lt;h2&gt;Distributed primitives&lt;/h2&gt; &lt;p&gt;To explain what we mean by new abstractions and primitives, here we compare them with the well-known object-oriented programming (OOP), and Java specifically. In the OOP universe, we have concepts such as class, object, package, inheritance, encapsulation, and polymorphism. Then the Java runtime provides specific features and guarantees on how it manages the lifecycle of our objects and the application as a whole.&lt;/p&gt; &lt;p&gt;The Java language and the Java Virtual Machine (JVM) provide local, in-process building blocks for creating applications. Kubernetes adds an entirely new dimension to this well-known mindset by offering a new set of distributed primitives and runtime for building distributed systems that spread across multiple nodes and processes. With Kubernetes at hand, we don’t rely only on the local primitives to implement the whole application behavior.&lt;/p&gt; &lt;p&gt;We still need to use the object-oriented building blocks to create the components of the distributed application, but we can also use Kubernetes primitives for some of the application behaviors. Table 1-1 shows how various development concepts are realized differently with local and distributed primitives in the JVM and Kubernetes, respectively.&lt;/p&gt; &lt;table border="1" cellpadding="1" cellspacing="1" width="731"&gt;&lt;caption&gt;Table 1: Local and distributed primitives.&lt;/caption&gt; &lt;thead&gt;&lt;tr&gt;&lt;th scope="col"&gt;Concept&lt;/th&gt; &lt;th scope="col"&gt;Local primitives&lt;/th&gt; &lt;th scope="col"&gt;Distributed primitive&lt;/th&gt; &lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;Behavior encapsulation &lt;/td&gt; &lt;td&gt;Class&lt;/td&gt; &lt;td&gt;Container image&lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Behavior instance &lt;/td&gt; &lt;td&gt;Object&lt;/td&gt; &lt;td&gt;Container&lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Unit of reuse &lt;/td&gt; &lt;td&gt;.jar&lt;/td&gt; &lt;td&gt;Container image&lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Composition&lt;/td&gt; &lt;td&gt;Class A contains Class B&lt;/td&gt; &lt;td&gt;Sidecar pattern&lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Inheritance &lt;/td&gt; &lt;td&gt;Class A extends Class B&lt;/td&gt; &lt;td&gt;A container’s FROM parent&lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Deployment unit &lt;/td&gt; &lt;td&gt;.jar/.war/.ear&lt;/td&gt; &lt;td&gt;image&lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Buildtime/Runtime isolation &lt;/td&gt; &lt;td&gt;Module, package, class&lt;/td&gt; &lt;td&gt;Pod&lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Initialization preconditions &lt;/td&gt; &lt;td&gt;Constructor&lt;/td&gt; &lt;td&gt;Namespace, Pod, container&lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Postinitialization trigger &lt;/td&gt; &lt;td&gt;Init-method&lt;/td&gt; &lt;td&gt;postStart&lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Predestroy trigger &lt;/td&gt; &lt;td&gt;Destroy-method&lt;/td&gt; &lt;td&gt;preStop&lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Cleanup procedure &lt;/td&gt; &lt;td&gt;finalize(), shutdown hook&lt;/td&gt; &lt;td&gt;-&lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Asynchronous and parallel execution &lt;/td&gt; &lt;td&gt;ThreadPoolExecutor, ForkJoinPool&lt;/td&gt; &lt;td&gt;Job&lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Periodic task &lt;/td&gt; &lt;td&gt;Timer, ScheduledExecutorService&lt;/td&gt; &lt;td&gt;CronJob&lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Background task &lt;/td&gt; &lt;td&gt;Daemon thread&lt;/td&gt; &lt;td&gt;DaemonSet&lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Configuration management&lt;/td&gt; &lt;td&gt;System.getenv(), Properties &lt;/td&gt; &lt;td&gt;ConfigMap, Secret&lt;/td&gt; &lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;The in-process primitives and the distributed primitives have commonalities, but they are not directly comparable and replaceable. They operate at different abstraction levels and have different preconditions and guarantees. Some primitives are supposed to be used together. For example, we still have to use classes to create objects and put them into container images. However, some other primitives such as CronJob in Kubernetes can completely replace the ExecutorService behavior in Java.&lt;/p&gt; &lt;p&gt;Next, let’s see a few distributed abstractions and primitives from Kubernetes that are especially interesting for application developers.&lt;/p&gt; &lt;h3&gt;Containers&lt;/h3&gt; &lt;p&gt;Containers are the building blocks for Kubernetes-based cloud native applications. If we make a comparison with OOP and Java, container images are like classes, and containers are like objects. The same way we can extend classes to reuse and alter behavior, we can have container images that extend other container images to reuse and alter behavior. The same way we can do object composition and use functionality, we can do container compositions by putting containers into a Pod and using collaborating containers.&lt;/p&gt; &lt;p&gt;If we continue the comparison, Kubernetes would be like the JVM but spread over multiple hosts, and it would be responsible for running and managing the containers.Init containers would be something like object constructors; DaemonSets would besimilar to daemon threads that run in the background (like the Java Garbage Collector,for example). A Pod would be something similar to an Inversion of Control (IoC) context (Spring Framework, for example), where multiple running objects share amanaged lifecycle and can access one another directly.&lt;/p&gt; &lt;p&gt;The parallel doesn’t go much further, but the point is that containers play a fundamental role in Kubernetes, and creating modularized, reusable, single-purpose container images is fundamental to the long-term success of any project and even the containers’ ecosystem as a whole. Apart from the technical characteristics of a container image that provide packaging and isolation, what does a container represent, and what is its purpose in the context of a distributed application? Here are a few suggestions on how to look at containers:&lt;/p&gt; &lt;ul&gt;&lt;li aria-level="1"&gt;A container image is the unit of functionality that addresses a single concern.&lt;/li&gt; &lt;li aria-level="1"&gt;A container image is owned by one team and has its own release cycle.&lt;/li&gt; &lt;li aria-level="1"&gt;A container image is self-contained and defines and carries its runtime dependencies.&lt;/li&gt; &lt;li aria-level="1"&gt;A container image is immutable, and once it is built, it does not change; it is configured.&lt;/li&gt; &lt;li aria-level="1"&gt;A container image defines its resource requirements and external dependencies.&lt;/li&gt; &lt;li aria-level="1"&gt;A container image has well-defined APIs to expose its functionality.&lt;/li&gt; &lt;li aria-level="1"&gt;A container typically runs as a single Unix process. &lt;/li&gt; &lt;li aria-level="1"&gt;A container is disposable and safe to scale up or down at any moment. In addition to all these characteristics, a proper container image is modular. It is parameterized and created for reuse in the different environments in which it is going to run. Having small, modular, and reusable container images leads to the creation of more specialized and stable container images in the long term, similar to a great reusable library in the programming language world.&lt;/li&gt; &lt;/ul&gt;&lt;h3&gt;Pods&lt;/h3&gt; &lt;p&gt;Looking at the characteristics of containers, we can see that they are a perfect match for implementing the microservices principles. A container image provides a single unit of functionality, belongs to a single team, has an independent release cycle, and provides deployment and runtime isolation. Most of the time, one microservice corresponds to one container image.&lt;/p&gt; &lt;p&gt;However, most cloud native platforms offer another primitive for managing the lifecycle of a group of containers—in Kubernetes, it is called a Pod. A Pod is an atomic unit of scheduling, deployment, and runtime isolation for a group of containers. All containers in a Pod are always scheduled to the same host, are deployed and scaled together, and can also share filesystem, networking, and process namespaces. This joint lifecycle allows the containers in a Pod to interact with one another over the filesystem or through networking via localhost or host interprocess communication mechanisms if desired (for performance reasons, for example). A Pod also represents a security boundary for an application. While it is possible to have containers with varying security parameters in the same Pod, typically all containers would have the same access level, network segmentation, and identity.&lt;/p&gt; &lt;p&gt;As you can see in Figure 1-2, at development and build time, a microservice corresponds to a container image that one team develops and releases. But at runtime, a microservice is represented by a Pod, which is the unit of deployment, placement, and scaling. The only way to run a container—whether for scale or migration—is through the Pod abstraction. Sometimes a Pod contains more than one container. In one such example, a containerized microservice uses a helper container at runtime, as Chapter 16, “Sidecar,” demonstrates.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/screenshot_2023-04-04_at_9.20.15_pm.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/screenshot_2023-04-04_at_9.20.15_pm.png?itok=oUkueEQq" width="600" height="384" alt="Diagram of a Pod managing two containers, one Java and one Python." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 2: A Pod as the deployment and management unit. Used with permission from Kubernetes Patterns, Second Edition by Bilgin Ibryam and Roland Huß (O’Reilly). Copyright 2023 Bilgin Ibryam and Roland Huß.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt;Containers, Pods, and their unique characteristics offer a new set of patterns and principles for designing microservices-based applications. We saw some of the characteristics of well-designed containers; now let’s look at some characteristics of a Pod:&lt;/p&gt; &lt;ul&gt;&lt;li aria-level="1"&gt;A Pod is the atomic unit of scheduling. That means the scheduler tries to find a host that satisfies the requirements of all containers that belong to the Pod (we cover some specifics around init containers in Chapter 15, “Init Container”). If you create a Pod with many containers, the scheduler needs to find a host that has enough resources to satisfy all container demands combined. This scheduling process is described in Chapter 6, “Automated Placement.”&lt;/li&gt; &lt;li aria-level="1"&gt;A Pod ensures colocation of containers. Thanks to the colocation, containers in the same Pod have additional means to interact with one another. The most common ways of communicating include using a shared local filesystem for exchanging data, using the localhost network interface, or using some host interprocess communication (IPC) mechanism for high-performance interactions.&lt;/li&gt; &lt;li aria-level="1"&gt;A Pod has an IP address, name, and port range that are shared by all containers belonging to it. That means containers in the same Pod have to be carefully configured to avoid port clashes, in the same way that parallel, running Unix processes have to take care when sharing the networking space on a host.&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;A Pod is the atom of Kubernetes where your application lives, but you don’t access Pods directly—that is where Services enter the scene.&lt;/p&gt; &lt;h3&gt;Services&lt;/h3&gt; &lt;p&gt;Pods are ephemeral. They come and go at any time for all sorts of reasons (e.g., scaling up and down, failing container health checks, node migrations). A Pod IP address is known only after it is scheduled and started on a node. A Pod can be rescheduled to a different node if the existing node it is running on is no longer healthy. This means the Pod’s network address may change over the life of an application, and there is a need for another primitive for discovery and load balancing.&lt;/p&gt; &lt;p&gt;That’s where the Kubernetes Services come into play. The Service is another simple but powerful Kubernetes abstraction that binds the Service name to an IP address and port number permanently. So a Service represents a named entry point for accessing an application. In the most common scenario, the Service serves as the entry point for a set of Pods, but that might not always be the case. The Service is a generic primitive, and it may also point to functionality provided outside the Kubernetes cluster. As such, the Service primitive can be used for Service discovery and load balancing, and it allows altering implementations and scaling without affecting Service consumers. We explain Services in detail in Chapter 13, “Service Discovery.”&lt;/p&gt; &lt;h3&gt;Labels&lt;/h3&gt; &lt;p&gt;We have seen that a microservice is a container image at build time but is represented by a Pod at runtime. So what is an application that consists of multiple microservices? Here, Kubernetes offers two more primitives that can help you define the concept of an application: labels and namespaces.&lt;/p&gt; &lt;p&gt;Before microservices, an application corresponded to a single deployment unit with a single versioning scheme and release cycle. There was a single file for an application in a .war, .ear, or some other packaging format. But then, applications were split into microservices, which are independently developed, released, run, restarted, or scaled. With microservices, the notion of an application diminishes, and there are no key artifacts or activities that we have to perform at the application level. But if you still need a way to indicate that some independent services belong to an application, labels can be used. Let’s imagine that we have split one monolithic application into three microservices and another one into two microservices.&lt;/p&gt; &lt;p&gt;We now have five Pod definitions (and maybe many more Pod instances) that are independent of the development and runtime points of view. However, we may still need to indicate that the first three Pods represent an application and the other two Pods represent another application. Even the Pods may be independent, to provide a business value, but they may depend on one another. For example, one Pod may contain the containers responsible for the frontend, and the other two Pods are responsible for providing the backend functionality. If either of these Pods is down, the application is useless from a business point of view. Using label selectors gives us the ability to query and identify a set of Pods and manage it as one logical unit. Figure 1-3 shows how you can use labels to group the parts of a distributed application into specific subsystems.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/screenshot_2023-04-04_at_9.19.06_pm.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/screenshot_2023-04-04_at_9.19.06_pm.png?itok=ICEnOykA" width="600" height="331" alt="Diagram of two distributed applications grouped into specific subsystems via labels." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 1-3. Labels used as an application identity for Pods. Used with permission from Kubernetes Patterns, Second Edition by Bilgin Ibryam and Roland Huß (O’Reilly). Copyright 2023 Bilgin Ibryam and Roland Huß.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt;Here are a few examples where labels can be useful:&lt;/p&gt; &lt;ul&gt;&lt;li aria-level="1"&gt;Labels are used by ReplicaSets to keep some instances of a specific Pod running. That means every Pod definition needs to have a unique combination of labels used for scheduling.&lt;/li&gt; &lt;li aria-level="1"&gt;Labels are also heavily used by the scheduler. The scheduler uses labels for colocating or spreading Pods to the nodes that satisfy the Pods’ requirements.&lt;/li&gt; &lt;li aria-level="1"&gt;A label can indicate a logical grouping of a set of Pods and give an application identity to them.&lt;/li&gt; &lt;li aria-level="1"&gt;In addition to the preceding typical use cases, labels can be used to store metadata. It may be difficult to predict what a label could be used for, but it is best to have enough labels to describe all important aspects of the Pods. For example, having labels to indicate the logical group of an application, the business characteristics and criticality, the specific runtime platform dependencies such as hardware architecture, or location preferences are all useful.&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;Later, these labels can be used by the scheduler for more fine-grained scheduling, or the same labels can be used from the command line for managing the matching Pods at scale. However, you should not go overboard and add too many labels in advance.&lt;/p&gt; &lt;p&gt;You can always add them later if needed. Removing labels is much riskier as there is no straightforward way of finding out what a label is used for and what unintended effect such an action may cause.&lt;/p&gt; &lt;h4&gt;Annotations&lt;/h4&gt; &lt;p&gt;Another primitive very similar to labels is the annotation. Like labels, annotations are organized as a map, but they are intended for specifying nonsearchable metadata and for machine usage rather than human.&lt;/p&gt; &lt;p&gt;The information on the annotations is not intended for querying and matching objects. Instead, it is intended for attaching additional metadata to objects from various tools and libraries we want to use. Some examples of using annotations include build IDs, release IDs, image information, timestamps, Git branch names, pull request numbers, image hashes, registry addresses, author names, tooling information, and more. So while labels are used primarily for query matching and performing actions on the matching resources, annotations are used to attach metadata that can be consumed by a machine.&lt;/p&gt; &lt;h3&gt;Namespaces&lt;/h3&gt; &lt;p&gt;Another primitive that can also help manage a group of resources is the Kubernetes namespace. As we have described, a namespace may seem similar to a label, but in reality, it is a very different primitive with different characteristics and purposes.&lt;/p&gt; &lt;p&gt;Kubernetes namespaces allow you to divide a Kubernetes cluster (which is usually spread across multiple hosts) into a logical pool of resources. Namespaces provide scopes for Kubernetes resources and a mechanism to apply authorizations and other policies to a subsection of the cluster. The most common use case of namespaces is representing different software environments such as development, testing, integration testing, or production. Namespaces can also be used to achieve multitenancy and provide isolation for team workspaces, projects, and even specific applications. But ultimately, for a greater isolation of certain environments, namespaces are not enough, and having separate clusters is common. Typically, there is one nonproduction Kubernetes cluster used for some environments (development, testing, and integration testing) and another production Kubernetes cluster to represent performance testing and production environments.&lt;/p&gt; &lt;p&gt;Let’s look at some of the characteristics of namespaces and how they can help us in different scenarios:&lt;/p&gt; &lt;ul&gt;&lt;li aria-level="1"&gt;A namespace is managed as a Kubernetes resource.&lt;/li&gt; &lt;li aria-level="1"&gt;A namespace provides scope for resources such as containers, Pods, Services, or ReplicaSets. The names of resources need to be unique within a namespace but not across them.&lt;/li&gt; &lt;li aria-level="1"&gt;By default, namespaces provide scope for resources, but nothing isolates those resources and prevents access from one resource to another. For example, a Pod from a development namespace can access another Pod from a production namespace as long as the Pod IP address is known. “Network isolation across namespaces for creating a lightweight multitenancy solution is described in Chapter 24, “Network Segmentation.”&lt;/li&gt; &lt;li aria-level="1"&gt;Some other resources, such as namespaces, nodes, and PersistentVolumes, do not belong to namespaces and should have unique cluster-wide names.&lt;/li&gt; &lt;li aria-level="1"&gt;Each Kubernetes Service belongs to a namespace and gets a corresponding Domain Name Service (DNS) record that has the namespace in the form of &lt;code&gt;&lt;service-name&gt;.&lt;namespace-name&gt;.svc.cluster.local&lt;/code&gt;. So the namespace name is in the URL of every Service belonging to the given namespace. That’s one reason it is vital to name namespaces wisely.&lt;/li&gt; &lt;li aria-level="1"&gt;ResourceQuotas provide constraints that limit the aggregated resource consumption per namespace. With ResourceQuotas, a cluster administrator can control the number of objects per type that are allowed in a namespace. For example, a developer namespace may allow only five ConfigMaps, five Secrets, five Services, five ReplicaSets, five PersistentVolumeClaims, and ten Pods.&lt;/li&gt; &lt;li aria-level="1"&gt;ResourceQuotas can also limit the total sum of computing resources we can request in a given namespace. For example, in a cluster with a capacity of 32 GB RAM and 16 cores, it is possible to allocate 16 GB RAM and 8 cores for the production namespace, 8 GB RAM and 4 cores for the staging environment, 4 GB RAM and 2 cores for development, and the same amount for testing namespaces. The ability to impose resource constraints decoupled from the shape and the limits of the underlying infrastructure is invaluable.&lt;/li&gt; &lt;/ul&gt;&lt;h2&gt;Discussion&lt;/h2&gt; &lt;p&gt;We’ve only briefly covered a few of the main Kubernetes concepts we use in this book. However, there are more primitives used by developers on a day-by-day basis. For example, if you create a containerized service, there are plenty of Kubernetes abstractions you can use to reap all the benefits of Kubernetes. Keep in mind, these are only a few of the objects used by application developers to integrate a containerized service into Kubernetes. There are plenty of other concepts used primarily by cluster administrators for managing Kubernetes. Figure 1-4 gives an overview of the main Kubernetes resources that are useful for developers.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/screenshot_2023-04-04_at_9.14.50_pm.png" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/screenshot_2023-04-04_at_9.14.50_pm.png?itok=kOtFuemK" width="600" height="427" alt="Diagram listing Kubernetes concepts for developers" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 4: Kubernetes concepts for developers. Used with permission from Kubernetes Patterns, Second Edition by Bilgin Ibryam and Roland Huß (O’Reilly). Copyright 2023 Bilgin Ibryam and Roland Huß.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt;With time, these new primitives give birth to new ways of solving problems, and some of these repetitive solutions become patterns. Throughout this book, rather than describing each Kubernetes resource in detail, we will focus on concepts that are proven as patterns.&lt;/p&gt; &lt;h2 id="download_gitops_cookbook-h2"&gt;Get the e-book: Kubernetes Patterns, 2nd Edition&lt;/h2&gt; &lt;p&gt;Kubernetes Patterns presents reusable patterns and principles for designing and implementing cloud native applications on Kubernetes. &lt;a href="https://developers.redhat.com/e-books/kubernetes-patterns-2nd-edition"&gt;&lt;strong&gt;Download the second edition e-book from Red Hat Developer.&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2023/04/05/kubernetes-patterns-path-cloud-native" title="Kubernetes Patterns: The path to cloud native"&gt;Kubernetes Patterns: The path to cloud native&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Bilgin Ibryam, Roland Huß</dc:creator><dc:date>2023-04-05T07:00:00Z</dc:date></entry><entry><title>Quarkus 3.0.0.CR2 released</title><link rel="alternate" href="&#xA;                https://quarkus.io/blog/quarkus-3-0-0-cr2-released/&#xA;            " /><author><name>Guillaume Smet (https://twitter.com/gsmet_)</name></author><id>https://quarkus.io/blog/quarkus-3-0-0-cr2-released/</id><updated>2023-04-05T00:00:00Z</updated><published>2023-04-05T00:00:00Z</published><summary type="html">Today, we released Quarkus 3.0.0.CR2, our last step before building the 3.0.0.Final bits. Please try it with your applications, the update is easy in a lot of cases, and report any problem to us by creating a GitHub issue. To upgrade your application to Quarkus 3.0, see the instructions below....</summary><dc:creator>Guillaume Smet (https://twitter.com/gsmet_)</dc:creator><dc:date>2023-04-05T00:00:00Z</dc:date></entry><entry><title>Update and upgrade JBoss EAP with Ansible</title><link rel="alternate" href="https://developers.redhat.com/articles/2023/04/04/update-and-upgrade-jboss-eap-ansible" /><author><name>Romain Pelisse</name></author><id>db3c5c1a-506e-450e-b437-eb0384a98609</id><updated>2023-04-04T07:00:00Z</updated><published>2023-04-04T07:00:00Z</published><summary type="html">&lt;p&gt;In this follow-up to &lt;a href="https://developers.redhat.com/articles/2022/02/08/automate-and-deploy-jboss-eap-cluster-ansible"&gt;Automate and deploy a JBoss EAP cluster with Ansible&lt;/a&gt;, we will explain how to maintain and keep those instances updated, again in a fully &lt;a href="https://developers.redhat.com/topics/automation"&gt;automated&lt;/a&gt; manner, leveraging Ansible and the &lt;a href="https://console.redhat.com/ansible/automation-hub/repo/published/redhat/eap/"&gt;Ansible collection for Red Hat JBoss Enterprise Application Platform (EAP)&lt;/a&gt;. &lt;/p&gt; &lt;p&gt;Indeed, it is critical to ensure that all JEE application server instances always be up to date, especially in regard to security fixes. Therefore, we’ll discuss not only how to apply patches to update the server but also how to perform an upgrade to migrate to a new major version.&lt;/p&gt; &lt;h2&gt;Prerequisites&lt;/h2&gt; &lt;p&gt;In the &lt;a href="https://developers.redhat.com/articles/2022/02/08/automate-and-deploy-jboss-eap-cluster-ansible"&gt;previous article&lt;/a&gt;, we used the following playbook to install the WildFly cluster using Ansible on one single host. However, in this article, we’ll use only one instance of JBoss EAP (and no longer WildFly) for simplicity's sake.&lt;/p&gt; &lt;p&gt;You can use the following playbook to install an instance of JBoss EAP:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-yaml"&gt;--- - name: Install EAP 7 hosts: all collections: - redhat.eap roles: - eap_install - eap_systemd&lt;/code&gt;&lt;/pre&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Note:&lt;/strong&gt; The playbook above uses the &lt;code&gt;redhat.eap&lt;/code&gt; certified collection instead of the upstream &lt;code&gt;middleware_automation.wildfly&lt;/code&gt; instance. The previous article used WildFly (the community version of the JEE application server) instead of JBoss EAP (the product supported by Red Hat). However, as updates are rarely produced for the upstream version (because of the fast release cycle, it’s easier to update to the next version), this article will focus on JBoss EAP, as product users often have to manage such updates.&lt;/p&gt; &lt;p&gt;For the playbook above to function as expected, you will need to install the collections &lt;code&gt;redhat.eap&lt;/code&gt; on the Ansible controller:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;# ansible-galaxy collection install redhat.eap Starting galaxy collection install process Process install dependency map Starting collection install process Downloading https://console.redhat.com/api/automation-hub/v3/plugin/ansible/content/published/collections/artifacts/redhat-eap-1.3.1.tar.gz to /root/.ansible/tmp/ansible-local-344ezcdnc0/tmpc0c7yq1u/redhat-eap-1.3.1-b5h7g9vf Downloading https://console.redhat.com/api/automation-hub/v3/plugin/ansible/content/published/collections/artifacts/redhat-redhat_csp_download-1.2.2.tar.gz to /root/.ansible/tmp/ansible-local-344ezcdnc0/tmpc0c7yq1u/redhat-redhat_csp_download-1.2.2-2kmr5p0m Installing 'redhat.eap:1.3.1' to '/root/.ansible/collections/ansible_collections/redhat/eap' redhat.eap:1.3.1 was installed successfully Installing 'redhat.redhat_csp_download:1.2.2' to '/root/.ansible/collections/ansible_collections/redhat/redhat_csp_download' redhat.redhat_csp_download:1.2.2 was installed successfully&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;As &lt;code&gt;redhat.eap&lt;/code&gt; is a certified collection only available to Red Hat customers, you need to configure the &lt;code&gt;ansible.cfg&lt;/code&gt; file to use Ansible Automation Hub so that the collection can be retrieved:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;# cat ansible.cfg [defaults] host_key_checking = False retry_files_enabled = False nocows = 1 [inventory] # fail more helpfully when the inventory file does not parse (Ansible 2.4+) unparsed_is_failed=true [galaxy] server_list = automation_hub, galaxy [galaxy_server.galaxy] url=https://galaxy.ansible.com/ [galaxy_server.automation_hub] url=https://cloud.redhat.com/api/automation-hub/ auth_url=https://sso.redhat.com/auth/realms/redhat-external/protocol/openid-connect/token token=&lt;your-token&gt;&lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;A bit of context first&lt;/h2&gt; &lt;p&gt;Before we continue, let's define what we mean (in this article) by update versus upgrade. &lt;/p&gt; &lt;h3&gt;Updates&lt;/h3&gt; &lt;p&gt;An &lt;strong&gt;update&lt;/strong&gt; to an existing JBoss EAP instance consists of the deployment of a series of fixes to the product’s code. Updates are provided to Red Hat customers through the &lt;a href="https://access.redhat.com/login?redirectTo=https%3A%2F%2Faccess.redhat.com"&gt;Red Hat Customer Portal&lt;/a&gt;. They contain a set of changes made against the JEE server code, either to fix an issue or address a security concern (or both). You need to use the JBoss CLI tool to deploy an update. However, as we’ll see soon, the &lt;code&gt;redhat.eap&lt;/code&gt; collection will take care of this for us.&lt;/p&gt; &lt;p&gt;It’s important to note that such an update only brings fixes to the server. No functionality changes (unless required to resolve a problem) nor API changes are performed. Therefore, an update does not change the major version of JBoss EAP—only the minor version. For instance, bringing JBoss EAP 7.4.0 to 7.4.6 (but not to 7.5).&lt;/p&gt; &lt;p&gt;Because an update to a more recent minor version only includes small changes, they rarely require modification to the applications hosted by JBoss EAP. They should be performed as quickly as possible in order to ensure the server can not be compromised by a known security issue.&lt;/p&gt; &lt;h3&gt;Upgrades&lt;/h3&gt; &lt;p&gt;An &lt;strong&gt;upgrade&lt;/strong&gt; is a more involved operation. Indeed, it comes with API changes and new features, meaning that, before being performed, the applications hosted by JBoss EAP should be tested against the new version and potentially adapted to work in this new context.&lt;/p&gt; &lt;p&gt;Also, an upgrade to JBoss EAP is a change of major version (EAP 7.3 to 7.4). This cannot be achieved by updating the files of the currently installed software. A complete, new installation needs to be performed, and the configuration, along with the hosted apps, needs to be migrated to this new root folder.&lt;/p&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Note: &lt;/strong&gt;This article focuses on the update and upgrade of the app server itself and, purposely, does not discuss configuration changes and application migration. On this front, too, the collection &lt;code&gt;redhat.eap&lt;/code&gt; provides some help by leveraging the &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_jboss_enterprise_application_platform/7.4/html-single/using_the_jboss_server_migration_tool/index"&gt;JBoss migration tool&lt;/a&gt;. This scenario will be the topic of a follow-up article.&lt;/p&gt; &lt;h2&gt;Applying a cumulative patch&lt;/h2&gt; &lt;p&gt;Let’s consider the following scenario:&lt;/p&gt; &lt;p&gt;A series of JBoss EAP 7.3.0 instances were freshly installed in order to perform tests before production. The tests were successful, and the team now wants to promote those servers from testing to preprod. The main requirement (regarding JBoss EAP) is to run the latest version of the server (7.3.10).&lt;/p&gt; &lt;p&gt;Here is the playbook used to fully automate the installation process:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-yaml"&gt;--- - name: "Update EAP to latest {{ eap_patch_version }}" hosts: eap_servers vars: eap_version: 7.3.0 eap_apply_cp: True eap_patch_version: 7.3.10 eap_instance_name: eap73 collections: - redhat.eap roles: - eap_install - eap_systemd&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This playbook relies entirely on the two roles provided by the &lt;code&gt;redhat.eap&lt;/code&gt; collection, to install EAP and start the associated service. The only information required is the server (major) version provided by the variable &lt;code&gt;eap_version&lt;/code&gt;. We also configured the collection to update this minor version (&lt;code&gt;eap_patch_apply&lt;/code&gt; set to &lt;code&gt;true&lt;/code&gt;) to the latest available minor version (7.3.10). We also added a variable to change the name of the service running the server to &lt;code&gt;eap73&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;Once this playbook has run successfully and Ansible has started the server, we can see that we are now running the latest version available of JBoss EAP 7.3, as proven by the following line of the &lt;code&gt;server.log&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;# tail -f /opt/jboss_eap/jboss-eap-7.3/standalone/log/server.log 2023-03-01 11:25:29,413 INFO [org.jboss.as.connector.subsystems.datasources] (MSC service thread 1-6) WFLYJCA0001: Bound data source [java:jboss/datasources/ExampleDS] 2023-03-01 11:25:29,483 INFO [org.jboss.as.patching] (MSC service thread 1-2) WFLYPAT0050: JBoss EAP cumulative patch ID is: jboss-eap-7.3.10.CP, one-off patches include: none 2023-03-01 11:25:29,494 WARN [org.jboss.as.domain.management.security] (MSC service thread 1-2) WFLYDM0111: Keystore /opt/jboss_eap/jboss-eap-7.3/standalone/configuration/application.keystore not found, it will be auto generated on first use with a self signed certificate for host localhost 2023-03-01 11:25:29,499 INFO [org.jboss.as.server.deployment.scanner] (MSC service thread 1-7) WFLYDS0013: Started FileSystemDeploymentService for directory /opt/jboss_eap/jboss-eap-7.3/standalone/deployments 2023-03-01 11:25:29,544 INFO [org.wildfly.extension.undertow] (MSC service thread 1-3) WFLYUT0006: Undertow HTTPS listener https listening on [0:0:0:0:0:0:0:0]:8443 2023-03-01 11:25:29,593 INFO [org.jboss.ws.common.management] (MSC service thread 1-5) JBWS022052: Starting JBossWS 5.3.0.Final-redhat-00001 (Apache CXF 3.3.12.redhat-00001) 2023-03-01 11:25:29,674 INFO [org.jboss.as.server] (Controller Boot Thread) WFLYSRV0212: Resuming server 2023-03-01 11:25:29,676 INFO [org.jboss.as] (Controller Boot Thread) WFLYSRV0025: JBoss EAP 7.3.10.GA (WildFly Core 10.1.25.Final-redhat-00001) started in 2300ms - Started 306 of 560 services (355 services are lazy, passive or on-demand) …&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Notes:&lt;/p&gt; &lt;ul&gt;&lt;li aria-level="1"&gt; &lt;p&gt;By default, the collection installs the latest major version of JBoss EAP (7.4.0). As we will discuss upgrading to the next major version in the second part of this article, we have purposely installed the previous major version of the JEE server.&lt;/p&gt; &lt;/li&gt; &lt;li aria-level="1"&gt;If the playbook is run again, no changes are reported, as the collection ensures that the setup of JBoss EAP is idempotent.&lt;/li&gt; &lt;/ul&gt;&lt;h2&gt;Upgrading to the next major version of JBoss EAP&lt;/h2&gt; &lt;p&gt;Minor upgrades contain only fixes. The actual changes are minimal. Features themselves are not modified, and no new ones are added unless a security fix requires it. In short, this means users can perform such updates on their system without fearing side effects or issues for the hosted applications. However, upgrading JBoss EAP to the next major version is a completely different scenario.&lt;/p&gt; &lt;p&gt;Let’s consider the following requirement. The JBoss EAP instances previously installed using Ansible have been targeted to be upgraded to 7.4 with the latest available minor version (7.4.10). Teams behind the hosted apps have tested and confirmed that no code changes are required; however, a plan is already in place if something goes wrong during the upgrade. Any instance having issues during the upgrade needs to downgrade and resume running the previous version.&lt;/p&gt; &lt;p&gt;Let’s build a playbook implementing such a strategy. First, it will stop the currently running instance of JBoss EAP on the target, then install and start the new version, using the same configuration template as the previous server. And, if anything goes wrong during this process, the existing service will be started.&lt;/p&gt; &lt;p&gt;Here is the playbook we will use to perform this migration:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-yaml"&gt;--- - name: "Update EAP to latest {{ eap_patch_version }}"   hosts: eap_servers   vars: eap_offline_install: True eap_apply_cp: True eap_patch_version: 7.4.9 eap_config_base: 'standalone.xml' eap_instance_name: eap74   collections: - redhat.eap   roles: - eap_systemd   pre_tasks: - name: "Ensure previous version of EAP is not running"    ansible.builtin.service:      name: eap73      state: stopped   tasks: - block:      - name: "Perform EAP {{ eap_patch_version }} installation"        ansible.builtin.include_role:          name: eap_install      - name: "Ensure EAP service is deployed and running."        ansible.builtin.include_role:          name: eap_systemd      - name: "Ensure EAP service is functional"        ansible.builtin.include_role:          name: eap_validation    rescue:      - name: "EAP upgrade failed, fallback to previous version"        ansible.builtin.service:          name: eap73          state: running&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The playbook above implements the migration process we described above. First, it stops the existing JBoss EAP server running on the target. Then, it leverages the &lt;code&gt;redhat.eap&lt;/code&gt; collection again to install the new version and start it as a service. To ensure that this instance is functional, it runs the &lt;code&gt;eap_validation&lt;/code&gt; role, also provided by the collection, that performs some basic sanity checks against the service.&lt;/p&gt; &lt;p&gt;Assuming nothing has failed during those three steps, the new server is running, and the migration has been completed successfully. If anything goes wrong, the new server is shut down, and the previous instance is restarted.&lt;/p&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Note:&lt;/strong&gt; This playbook is not idempotent and is aimed at being run only for migration purposes. This is both for the sake of simplicity and readability.&lt;/p&gt; &lt;h2&gt;Performing the upgrade and update without downtime&lt;/h2&gt; &lt;p&gt;Most of the time, updating and upgrading JBoss EAP will require restarting the service, which implies some downtime. However, if there is more than one instance of JBoss EAP to update, it is possible to use a powerful Ansible feature to avoid any downtime (assuming there is a smart proxy in front of the JBoss EAP farm, such as &lt;code&gt;httpd&lt;/code&gt; using &lt;code&gt;mod_cluster&lt;/code&gt;).&lt;/p&gt; &lt;p&gt;By default, Ansible will try to connect to any hosts belonging to the &lt;code&gt;eap_servers&lt;/code&gt; group and perform the update and the upgrade in parallel. If everything goes according to plan, there is still a risk of downtime, as the server might be restarting at the same time. If anything goes wrong, most, if not all, will need to roll back to the previous version, leading to even more chances of downtime.&lt;/p&gt; &lt;p&gt;However, this &lt;a href="https://docs.ansible.com/ansible/latest/playbook_guide/playbooks_strategies.html"&gt;execution strategy&lt;/a&gt; can be configured by adding the keyword &lt;code&gt;serial&lt;/code&gt; to the playbook. This will configure how Ansible will operate on the list of servers to connect and execute by batch, only a subset of them at once. With this feature, we can implement the following approach:&lt;/p&gt; &lt;ul&gt;&lt;li aria-level="1"&gt;Update (or upgrade) on target;&lt;/li&gt; &lt;li aria-level="1"&gt;Update (or upgrade) one-third of the entire farm;&lt;/li&gt; &lt;li aria-level="1"&gt;Update (or upgrade) the rest of the targets.&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;Such a strategy offers a lot of peace of mind; if the first machine to be targeted fails to update or upgrade, you can stop the process here and investigate what went wrong. The rest of the servers are still running without any risk of downtime. The same applies to the next batch. If something goes wrong with the first third of the servers, then most of the farm is still running the old version, uninterrupted.&lt;/p&gt; &lt;p&gt;To implement this strategy in our upgrade playbook, we only need to add the attribute &lt;code&gt;serial&lt;/code&gt;. We valorize it using a list containing three values, as shown below:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-yaml"&gt;--- - name: "Update EAP to latest {{ eap_patch_version }}" hosts: all serial: - 1 - 30% - 70% vars: eap_offline_install: True eap_apply_cp: True eap_patch_version: 7.4.9 eap_instance_name: eap74 collections: - redhat.eap roles: - eap_install - eap_systemd pre_tasks: - name: "Ensure previous version of EAP is not running" ansible.builtin.service: name: eap73 state: stopped tasks: - block: - name: "Perform EAP {{ eap_patch_version }} installation" ansible.builtin.include_role: name: eap_install - name: "Ensure EAP service is deployed and running." ansible.builtin.include_role: name: eap_systemd - name: "Ensure EAP service is functional" ansible.builtin.include_role: name: eap_validation rescue: - name: "EAP upgrade failed, fallback to previous version" ansible.builtin.service: name: eap73 state: running&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Note that the values within the serial property can indeed be a mix of integers (1) and percentages.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;With the heavy lifting of the server installation managed by the &lt;code&gt;redhat.eap&lt;/code&gt; collection and the primitives provided by Ansible, we have implemented a sound strategy to perform updates and upgrades on a potentially very large farm of instances.&lt;/p&gt; &lt;p&gt;The two playbooks we displayed in this article are both short and simple to understand. Their content focuses only on the environment specificity (version executed, execution strategy), and the inner workings of EAP are fully encapsulated inside the collection, which provides peace of mind in what would typically be a complex operation and process.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2023/04/04/update-and-upgrade-jboss-eap-ansible" title="Update and upgrade JBoss EAP with Ansible"&gt;Update and upgrade JBoss EAP with Ansible&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Romain Pelisse</dc:creator><dc:date>2023-04-04T07:00:00Z</dc:date></entry><entry><title>Quarkus 2.16.6.Final released - Maintenance release</title><link rel="alternate" href="&#xA;                https://quarkus.io/blog/quarkus-2-16-6-final-released/&#xA;            " /><author><name>Guillaume Smet (https://twitter.com/gsmet_)</name></author><id>https://quarkus.io/blog/quarkus-2-16-6-final-released/</id><updated>2023-04-04T00:00:00Z</updated><published>2023-04-04T00:00:00Z</published><summary type="html">We released Quarkus 2.16.6.Final, the fsixthifth maintenance release of our 2.16 release train. As usual, it contains bugfixes and documentation improvements. It should be a safe upgrade for anyone already using 2.16. If you are not already using 2.16, please refer to our migration guide. Full changelog You can get...</summary><dc:creator>Guillaume Smet (https://twitter.com/gsmet_)</dc:creator><dc:date>2023-04-04T00:00:00Z</dc:date></entry><entry><title>A leaner &lt;iostream&gt; in libstdc++ for GCC 13</title><link rel="alternate" href="https://developers.redhat.com/articles/2023/04/03/leaner-libstdc-gcc-13" /><author><name>Patrick Palka</name></author><id>bc755caf-cf65-46cf-a695-91450fff9c9c</id><updated>2023-04-03T07:00:00Z</updated><published>2023-04-03T07:00:00Z</published><summary type="html">&lt;p&gt;One of the many enhancements coming to libstdc++ shipped in GCC 13, which is expected to be released in May 2023, addresses an old pain point of the &lt;code&gt;&lt;iostream&gt;&lt;/code&gt; header. In current versions of libstdc++, including &lt;code&gt;&lt;iostream&gt;&lt;/code&gt; in a translation unit (TU) introduces a global constructor into the compiled object file, one that is responsible for initializing the standard stream objects &lt;code&gt;std::cout&lt;/code&gt;, &lt;code&gt;std::cin&lt;/code&gt;, etc., on program startup.&lt;/p&gt; &lt;p&gt;In libstdc++ for GCC 13, this will be no more, as we’ve moved the initialization of the standard stream objects into the shared library. The benefit of this is reduced executable size, improved link times, and improved startup times for &lt;a href="https://developers.redhat.com/topics/c"&gt;C++&lt;/a&gt; programs that make heavy use of &lt;code&gt;&lt;iostream&gt;&lt;/code&gt;.&lt;/p&gt; &lt;h3&gt;An example&lt;/h3&gt; &lt;p&gt;Consider the canonical C++ Hello World program:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;#include &lt;iostream&gt; int main() {     std::cout &lt;&lt; "Hello world!\n"; }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;At some point in your journey as a C++ programmer, you've probably compiled this program and inspected the resulting assembly.  Using GCC 12.2 as the compiler yields &lt;a href="https://godbolt.org/z/1j864zWoo"&gt;the following assembly&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;     .LC0:      .string "Hello world!\n"     main:       subq $8, %rsp       movl $.LC0, %esi       movl $_ZSt4cout, %edi # std::cout       call std::basic_ostream&lt;char, std::char_traits&lt;char&gt; &gt;&amp; std::operator&lt;&lt; &lt;std::char_traits&lt;char&gt; &gt;(std::basic_ostream&lt;char, std::char_traits&lt;char&gt; &gt;&amp;, char const*)       movl $0, %eax       addq $8, %rsp       ret     _GLOBAL__sub_I_main:       subq $8, %rsp       movl $_ZStL8__ioinit, %edi # std::__ioinit       call std::ios_base::Init::Init() [complete object constructor]       movl $__dso_handle, %edx       movl $_ZStL8__ioinit, %esi # std::__ioinit       movl $_ZNSt8ios_base4InitD1Ev, %edi # std::ios_base::Init::~Init()       call __cxa_atexit       addq $8, %rsp       ret&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This is a surprising amount of assembly code for Hello World.  Notably, alongside the expected &lt;code&gt;main&lt;/code&gt; definition which invokes the appropriate &lt;code&gt;operator&lt;&lt;&lt;/code&gt; overload, somehow a global initializer (the &lt;code&gt;_GLOBAL__sub_I_main&lt;/code&gt; symbol) snuck in, one which seems to construct an object &lt;code&gt;__ioinit&lt;/code&gt; of type &lt;code&gt;std::ios_base::Init&lt;/code&gt; (and schedules destruction of the object at program exit).  One might wonder, how did that get there and what is its purpose?&lt;/p&gt; &lt;p&gt;In contrast, if we compile with GCC trunk, we instead get &lt;a href="https://godbolt.org/z/4WPrsPc11"&gt;the following&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;.LC0:      .string "Hello world!\n"     main:       subq $8, %rsp       movl $.LC0, %esi       movl $_ZSt4cout, %edi       call std::basic_ostream&lt;char, std::char_traits&lt;char&gt; &gt;&amp; std::operator&lt;&lt; &lt;std::char_traits&lt;char&gt; &gt;(std::basic_ostream&lt;char, std::char_traits&lt;char&gt; &gt;&amp;, char const*)       movl $0, %eax       addq $8, %rsp       ret&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This notably emits no such global initializer (and is much more in line with what one would expect the resulting assembly to be).  Instead, an equivalent initializer is present in &lt;code&gt;libstdc++.so&lt;/code&gt; and will run upon dynamic loading of the library (we’ll touch upon the details in a later section).&lt;/p&gt; &lt;h3&gt;Why the __ioinit object&lt;/h3&gt; &lt;p&gt;The global initializer we see in the GCC 12.2 output corresponds to the static global object &lt;code&gt;__ioinit&lt;/code&gt; that's defined in &lt;code&gt;&lt;iostream&gt;&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;  // For construction of filebuffers for cout, cin, cerr, clog et. al.   static ios_base::Init __ioinit;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;As the comment above it suggests, the purpose of this object is ultimately to ensure that the standard stream objects &lt;code&gt;std::cout&lt;/code&gt;, &lt;code&gt;std::cin&lt;/code&gt;, etc., are properly initialized (via the &lt;code&gt;ios_base::Init::Init&lt;/code&gt; constructor) before they are used in the program by either &lt;code&gt;main()&lt;/code&gt; proper or earlier during the initialization of another global object.&lt;/p&gt; &lt;p&gt;Thus, including &lt;code&gt;&lt;iostream&gt;&lt;/code&gt; implicitly defines a static global object of type &lt;code&gt;ios_base::Init&lt;/code&gt; within the TU.  This approach gets the job done because C++ guarantees global objects within one TU are initialized in the order in which they're defined, so we can ensure that the stream objects are usable even during the startup (and shutdown) phase of a program, e.g.:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;    #include &lt;iostream&gt;     struct A {         A() { std::cout &lt;&lt; "A::A()\n"; }         ~A() { std::cout &lt;&lt; "A::~A()\n"; }     };     static A a; // Works because __ioinit is defined within the TU first&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;A tempting and more obvious alternative might be to perform initialization of the standard stream objects in the stream objects' constructors themselves (which effectively must be defined in the compiled-in part of the library – &lt;code&gt;libstdc++.so&lt;/code&gt; or &lt;code&gt;libstdc++.a&lt;/code&gt; -- rather than in a header because &lt;code&gt;std::cout,&lt;/code&gt; et al. are not &lt;code&gt;inline&lt;/code&gt; objects).  But this won't work because C++ gives no guarantees about global object initialization order across TUs, and neither do linkers by default give similar guarantees across object files.&lt;/p&gt; &lt;p&gt;While the static global approach works, there's a significant drawback: a distinct global object will be defined for every TU that includes &lt;code&gt;&lt;iostream&gt;&lt;/code&gt; and will persist all the way into the final executable.  Thus at program startup, the constructor (and destructor) for &lt;code&gt;ios_base::Init&lt;/code&gt; will redundantly run once for every constituent TU that includes &lt;code&gt;&lt;iostream&gt;&lt;/code&gt;, leading to code bloat and slower link and startup times.&lt;/p&gt; &lt;h3&gt;A better approach&lt;/h3&gt; &lt;p&gt;In GCC 13, we essentially moved the &lt;code&gt;__ioinit&lt;/code&gt; definition:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;  static ios_base::Init __ioinit;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;from the &lt;code&gt;&lt;iostream&gt;&lt;/code&gt; header and into the compiled library sources.  This was carefully done with the help of the non-standard &lt;a href="https://gcc.gnu.org/onlinedocs/gcc/C_002b_002b-Attributes.html#index-init_005fpriority-variable-attribute"&gt;&lt;code&gt;init_priority&lt;/code&gt; attribute&lt;/a&gt;, which gives more control over inter-TU object initialization order than what standard C++ provides.  As a result, TUs that include &lt;code&gt;&lt;iostream&gt;&lt;/code&gt; are no longer encumbered by this "invisible" global &lt;code&gt;__ioinit&lt;/code&gt; object.&lt;/p&gt; &lt;p&gt;As you might expect, this change is backward-compatible with programs compiled against earlier versions of libstdc++ because changing the &lt;code&gt;&lt;iostream&gt;&lt;/code&gt; header won’t affect TUs that were compiled against the older &lt;code&gt;&lt;iostream&gt;&lt;/code&gt; header, and the initialization that is now also performed within the compiled library is idempotent.&lt;/p&gt; &lt;p&gt;Most modern platforms support the &lt;code&gt;init_priority&lt;/code&gt; attribute; on platforms that lack such support, we fall back to the old way of defining &lt;code&gt;__ioinit&lt;/code&gt; in &lt;code&gt;&lt;iostream&gt;&lt;/code&gt;.&lt;/p&gt; &lt;h3&gt;Conclusion&lt;/h3&gt; &lt;p&gt;In GCC 13's libstdc++, we've revisited an age-old implementation decision of how the standard stream objects get defined.  The new approach is better in many ways, and it is more in line with the zero-cost abstraction philosophy of C++. This is one of many enhancements to look forward to in the upcoming release of GCC 13; a more complete list of changes can be found at &lt;a href="https://gcc.gnu.org/gcc-13/changes.html#libstdcxx"&gt;gnu.org&lt;/a&gt;.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2023/04/03/leaner-libstdc-gcc-13" title="A leaner &lt;iostream&gt; in libstdc++ for GCC 13"&gt;A leaner &lt;iostream&gt; in libstdc++ for GCC 13&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Patrick Palka</dc:creator><dc:date>2023-04-03T07:00:00Z</dc:date></entry><entry><title>Try Camel K in the Developer Sandbox for Red Hat OpenShift</title><link rel="alternate" href="https://developers.redhat.com/articles/2023/03/30/try-camel-k-developer-sandbox-red-hat-openshift" /><author><name>Bruno Meseguer</name></author><id>6b606d6a-f034-4db1-b7a6-a4fddb3e6c1c</id><updated>2023-03-30T07:01:00Z</updated><published>2023-03-30T07:01:00Z</published><summary type="html">&lt;p&gt;You can now try &lt;a href="https://developers.redhat.com/topics/camel-k"&gt;Camel K&lt;/a&gt; in the &lt;a href="https://developers.redhat.com/developer-sandbox/"&gt;Developer Sandbox for Red Hat OpenShift&lt;/a&gt;, an &lt;a href="https://developers.redhat.com/products/openshift/overview"&gt;OpenShift&lt;/a&gt; environment you can access for a free, hands-on experience in building and deploying cloud-native applications quickly. This article will guide you to the Developer Sandbox and through a Camel K integration in a fully web-based experience—no local installs needed.&lt;/p&gt; &lt;p&gt;If you are unfamiliar with Camel K, it is a subproject of Apache Camel, which many know as the Swiss Army knife of integration. Camel K simplifies the process of running cloud-native integration flows in &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt; environments.&lt;/p&gt; &lt;h2&gt;What’s so special about Camel K?&lt;/h2&gt; &lt;p&gt;Many organizations and developers implement &lt;a href="https://developers.redhat.com/topics/microservices/"&gt;microservices&lt;/a&gt; with varied languages and frameworks, but they usually forget the existence of purpose-built technologies such as Apache Camel, packed with hundreds of connectors and out-of-the-box patterns to resolve typical and challenging integration scenarios, such as content-based routing, splitting or data aggregation, protocol bridging, data transformation, and so on.&lt;/p&gt; &lt;p&gt;Camel K was designed to encapsulate the key concepts of running integrations on &lt;a href="https://developers.redhat.com/topics/containers"&gt;containers&lt;/a&gt;, providing a significant degree of automation to simplify the process of creating, building, deploying, and operating integration flows in Kubernetes environments.&lt;/p&gt; &lt;p&gt;Usually, applications are defined in a complex project tree and include dependency descriptors to incorporate libraries necessary to run the application. Camel K, on the other hand, aims to simplify the project to let the developer focus on the process flow definition. It automatically analyzes the code to find needed dependencies and only requires the essential flow definitions and resources from the developer.&lt;/p&gt; &lt;h2&gt;Access the Developer Sandbox&lt;/h2&gt; &lt;p&gt;Follow these instructions to get started in the Developer Sandbox: &lt;a href="https://developers.redhat.com/articles/2023/03/09/how-access-developer-sandbox-red-hat-openshift#" target="_blank"&gt;How to access the Developer Sandbox for Red Hat OpenShift&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Once you have your browser connected to the Developer Sandbox console, you’ll be all set to start the first part of this article’s tutorial.&lt;/p&gt; &lt;h2&gt;Part 1: Roll the dice&lt;/h2&gt; &lt;p&gt;The most straightforward way to get started with Camel K is from the Developer view. Follow the instructions below to deploy a “Hello world” example.&lt;/p&gt; &lt;p&gt;From the Developer view, click &lt;strong&gt;+Add&lt;/strong&gt; in the left menu, and scroll down to the Developer Catalog to find the &lt;strong&gt;Operator Backed&lt;/strong&gt; category, as shown in Figure 1.&lt;/p&gt; &lt;p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;img alt="add operator" data-entity-type="file" data-entity-uuid="b4a63ecc-9494-4979-a1d6-9ae539765b2f" height="577" src="https://developers.redhat.com/sites/default/files/inline-images/08-add-operator-backed.jpg" width="431" loading="lazy" /&gt;&lt;figcaption class="rhd-c-caption"&gt;Figure 1: Add 'Operator Backed' from the Developer Catalog.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/p&gt; &lt;p&gt;Locate the &lt;strong&gt;Integration&lt;/strong&gt; resource in the catalog, as illustrated in Figure 2:&lt;/p&gt; &lt;ul&gt;&lt;li aria-level="1"&gt;Use the filter (type “integration”)&lt;/li&gt; &lt;li aria-level="1"&gt;Click on the &lt;strong&gt;Integration &lt;/strong&gt;tile, then click the blue &lt;strong&gt;Create&lt;/strong&gt; button that appears from the right.&lt;/li&gt; &lt;/ul&gt;&lt;p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;img alt="select integration" data-entity-type="file" data-entity-uuid="c31ad4a5-5acf-4e59-ad5f-f2445573bef5" src="https://developers.redhat.com/sites/default/files/inline-images/09-select-integration.jpg" width="1000" height="649" loading="lazy" /&gt;&lt;figcaption class="rhd-c-caption"&gt;Figure 2: Find the Integration resource.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/p&gt; &lt;p&gt;Click on the &lt;strong&gt;Configure via YAML view&lt;/strong&gt; radio button. You will then be presented with a definition screen similar to the one shown in Figure 3.&lt;/p&gt; &lt;p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;img alt="YAML view" data-entity-type="file" data-entity-uuid="0c9c01eb-0d48-42c2-bc61-eeb23a0e278e" src="https://developers.redhat.com/sites/default/files/inline-images/10-create-integration.png" width="1000" height="1602" loading="lazy" /&gt;&lt;figcaption class="rhd-c-caption"&gt;Figure 3: YAML view.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/p&gt; &lt;p&gt;By selecting the &lt;strong&gt;YAML view&lt;/strong&gt;, the interface lets you edit the definition and create the integration directly on the screen. This is a manual procedure that is very helpful when playing with the technology for the first time.&lt;/p&gt; &lt;p&gt;The default Camel route definition is very simplistic; let’s make it a bit more interesting so that you can start experiencing the Camel K operator in action.&lt;/p&gt; &lt;p&gt;Replace the default Camel route (&lt;code&gt;from&lt;/code&gt; definition) with the following snippet:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-yaml"&gt; - from: uri: 'platform-http:/roll-dice' steps: - set-body: simple: 'roll: ${random(1,6)}'&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;In the preceding code, the &lt;code&gt;from&lt;/code&gt; element exposes an HTTP entry point for a service called &lt;code&gt;roll-dice&lt;/code&gt; that will serve random numbers from 1 to 6 when clients submit HTTP requests.&lt;/p&gt; &lt;p&gt;Click &lt;strong&gt;Create&lt;/strong&gt;.&lt;/p&gt; &lt;p&gt;When you create an integration as just described, the definition gets stored in your OpenShift project (namespace). Behind the scenes, the Camel K operator, deployed elsewhere, has visibility and picks up your definition to trigger a build and deployment on your project. This process takes some time.&lt;/p&gt; &lt;p&gt;To monitor the state of the integration deployment, open a terminal from where you can obtain information from the environment via the command line. Click the terminal icon at the top of your screen and then click the &lt;strong&gt;Start&lt;/strong&gt; button below to initialize the terminal, as shown in Figure 4.&lt;/p&gt; &lt;p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;img alt="Open the terminal for Camel K" data-entity-type="file" data-entity-uuid="9166decd-d6e5-4c74-8a7d-e09488d53336" src="https://developers.redhat.com/sites/default/files/inline-images/11-open-terminal.jpg" width="1000" height="910" loading="lazy" /&gt;&lt;figcaption class="rhd-c-caption"&gt;Figure 4: Initialize the terminal.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/p&gt; &lt;p&gt;When you start the terminal, a new pod deploys. This is where your terminal is running.&lt;/p&gt; &lt;p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;img alt="Work terminal" data-entity-type="file" data-entity-uuid="a77e2973-d6c0-495b-8741-3df6af2f59d8" src="https://developers.redhat.com/sites/default/files/inline-images/12-work-terminal.jpg" width="1000" height="941" loading="lazy" /&gt;&lt;figcaption class="rhd-c-caption"&gt;Figure 5: Terminal running.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/p&gt; &lt;p&gt;On your terminal, type:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-apache"&gt;oc get integration -w&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The flag &lt;code&gt;-w&lt;/code&gt; indicates to watch the resource for changes.&lt;/p&gt; &lt;p&gt;As the work progresses, its state will transition from &lt;code&gt;Building Kit&lt;/code&gt; to &lt;code&gt;Deploying&lt;/code&gt; to &lt;code&gt;Running&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;You should see an output similar to the following:&lt;/p&gt; &lt;pre&gt; bash-4.4 ~ $ oc get integration -w NAME PHASE KIT REPLICAS example Building Kit kit-cdl6pa788ih7pmdvn6c0 example Deploying kit-cdl6pa788ih7pmdvn6c0 example Running kit-cdl6pa788ih7pmdvn6c0 0 example Running kit-cdl6pa788ih7pmdvn6c0 1 example Running kit-cdl6pa788ih7pmdvn6c0 1 example Running kit-cdl6pa788ih7pmdvn6c0 1&lt;/pre&gt; &lt;p&gt; &lt;/p&gt; &lt;p&gt;When the deployment completes, a new pod will run your integration definition:&lt;/p&gt; &lt;p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;img alt="Pod running the example" data-entity-type="file" data-entity-uuid="a36b66c3-65f3-48ca-9c2d-25ba4f3d738f" height="249" src="https://developers.redhat.com/sites/default/files/inline-images/13-hello-world.png" width="430" loading="lazy" /&gt;&lt;figcaption class="rhd-c-caption"&gt;Figure 6: Pod running the example.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/p&gt; &lt;p&gt;What’s interesting in this deployment is that the Camel K operator has the intelligence to recognize you’re exposing an HTTP endpoint and automatically deploys a Kubernetes &lt;a href="https://kubernetes.io/docs/concepts/services-networking/service/" target="_blank"&gt;service&lt;/a&gt; named &lt;code&gt;example&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;To test the service from within OpenShift, you can invoke it from the terminal. Enter the following cURL command and execute:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-yaml"&gt;curl http://example/roll-dice&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The command should return the value produced by the Camel integration. Executing it multiple times will produce random numbers from 1-6, simulating the dice rolling each time.&lt;/p&gt; &lt;p&gt;By default, the Developer Sandbox does not expose the service automatically to external consumers. If you want the service to be externally accessible, you can simply enable an OpenShift &lt;a href="https://docs.openshift.com/container-platform/4.11/networking/routes/route-configuration.html target="&gt;route&lt;/a&gt; by running the following command:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-apache"&gt;oc expose service example --path=/roll-dice&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The command above uses the OpenShift client &lt;code&gt;oc&lt;/code&gt; to create a route that points to your new &lt;em&gt;Camel&lt;/em&gt; example service, to expose to the external world.&lt;/p&gt; &lt;p&gt;Now you can also call the &lt;code&gt;roll-dice&lt;/code&gt; service from your browser as if you were an external consumer. Notice the little icon attached to the Camel’s pod round graphic; click on it.&lt;/p&gt; &lt;p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;img alt="Camel K pod" data-entity-type="file" data-entity-uuid="9faa004d-5d6a-48b4-a55d-8e2e253d1a92" height="242" src="https://developers.redhat.com/sites/default/files/inline-images/14-hello-world-test.png" width="220" loading="lazy" /&gt;&lt;figcaption class="rhd-c-caption"&gt;Figure 7: Camel example service.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/p&gt; &lt;p&gt;If your browser renders "Resource not found" or another error message, make sure your address bar uses &lt;code&gt;http&lt;/code&gt; (not HTTPS), and include the service path &lt;code&gt;/roll-dice&lt;/code&gt; at the end of the URL, similar to:&lt;/p&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;&lt;code&gt;http://&lt;/code&gt;&lt;/strong&gt;...&lt;long address value here&gt;...&lt;strong&gt;&lt;code&gt;/roll-dice&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;In your browser, it should look similar to Figure 8.&lt;/p&gt; &lt;p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;img alt="browser roll dice" data-entity-type="file" data-entity-uuid="d19d0215-234a-405e-b7b9-12a7583edfca" src="https://developers.redhat.com/sites/default/files/inline-images/15-hello-world-test-browser.jpg" width="1007" height="239" loading="lazy" /&gt;&lt;figcaption class="rhd-c-caption"&gt;Figure 8: The browser.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/p&gt; &lt;p&gt;If you click the &lt;strong&gt;Reload &lt;/strong&gt;button several times, you’ll see different values displayed.&lt;/p&gt; &lt;p&gt;When you’re done, to clean up your working project, delete your integration with the simple command shown below:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-apache"&gt;oc delete integration example&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;You also need to delete the route you manually created by executing:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-apache"&gt;oc delete route example&lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Part 2: Inside OpenShift Dev Spaces&lt;/h2&gt; &lt;p&gt;If you want to play with Camel K in a more traditional developer workflow using a code editor and a terminal, the Developer Sandbox ships with an entire web-based IDE called &lt;a href="https://developers.redhat.com/products/openshift-dev-spaces/overview target="&gt;Red Hat OpenShift Dev Spaces&lt;/a&gt; (formerly Red Hat CodeReady Workspaces).&lt;/p&gt; &lt;h3&gt;Set up your dev environment with the Camel tutorials&lt;/h3&gt; &lt;p&gt;The animated sequence in Figure 9 illustrates the actions to follow to open your development environment along with your tutorial instructions.&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/open-tutorials.gif"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/open-tutorials.gif" width="985" height="490" alt="gif to open dev tutorial" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 9: The Dev Spaces UI.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Follow these steps:&lt;/p&gt; &lt;ol&gt;&lt;li aria-level="1"&gt;From the web console, click the &lt;strong&gt;Applications&lt;/strong&gt; icon as shown in Figure 9 (marked 1).&lt;/li&gt; &lt;li aria-level="1"&gt;Select &lt;strong&gt;Red Hat OpenShift Dev Spaces&lt;/strong&gt; (2).&lt;br /&gt; You will be prompted to log in and Authorize Access; select the "Allow selected permissions" option.&lt;/li&gt; &lt;li aria-level="1"&gt; &lt;p&gt;When the Create Workspace dashboard in OpenShift Dev Spaces opens, copy the snippet below:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-http"&gt;https://github.com/RedHat-Middleware-Workshops/devsandbox-camel.git&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Then, paste it into the &lt;strong&gt;Git Repo URL&lt;/strong&gt; field (3).&lt;/p&gt; &lt;/li&gt; &lt;li aria-level="1"&gt;Click &lt;strong&gt;Create &amp; Open&lt;/strong&gt; (4).&lt;/li&gt; &lt;li aria-level="1"&gt;When the workspace finishes provisioning and the IDE opens, click the deployable Endpoints accordion (5).&lt;/li&gt; &lt;li aria-level="1"&gt;Then, click on the icon (6), which opens the tutorial in a new browser tab.&lt;/li&gt; &lt;li aria-level="1"&gt;Choose the tutorial indicated in the next section.&lt;/li&gt; &lt;/ol&gt;&lt;h3&gt;Start the Camel K tutorial&lt;/h3&gt; &lt;p&gt;Select the &lt;strong&gt;Camel K - User Demo &lt;/strong&gt;tile, highlighted in Figure 10.&lt;/p&gt; &lt;p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;img alt="Camel K tutorial" data-entity-type="file" data-entity-uuid="45527a98-ac86-4d78-b31b-f647d1ab83c2" height="497" src="https://developers.redhat.com/sites/default/files/inline-images/20-solution-explorer.jpg" width="755" loading="lazy" /&gt;&lt;figcaption class="rhd-c-caption"&gt;Figure 10: Locating the Camel K tutorial.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/p&gt; &lt;p&gt;When you click on the tile, the Solution Explorer will show the lab introduction and the exercise chapters included, which you should be able to complete in around 15 minutes.&lt;/p&gt; &lt;p&gt;The aim of this use case demo is to help you get started with the basics of Camel K and play in the Developer Sandbox. For that reason, the use case selected is simple and friendly. The sequence diagram in Figure 11 illustrates the flow you’re about to create; you’ll get to see for yourself how little effort is required to complete it.&lt;/p&gt; &lt;p&gt; &lt;figure class="text-align-center align-center rhd-u-has-filter-caption" role="group"&gt;&lt;img alt="sequence diagram" data-entity-type="file" data-entity-uuid="fd692789-8aff-4eda-86d1-ce326bb75854" src="https://developers.redhat.com/sites/default/files/inline-images/21-seq-diagram.jpg" width="441" height="432" loading="lazy" /&gt;&lt;figcaption class="rhd-c-caption"&gt;Figure 11: The Camel K flow.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/p&gt; &lt;p&gt;Enjoy the Camel ride!&lt;/p&gt; &lt;h2&gt;More Apache Camel resources&lt;/h2&gt; &lt;p&gt;This article ends here, but this should only be the start of your journey with Apache Camel. The Developer Sandbox for Red Hat OpenShift gives you the opportunity to play on a Kubernetes-based application platform with an integrated developer IDE (OpenShift Dev Spaces).&lt;/p&gt; &lt;p&gt;With your browser alone, you can quickly complete the Camel K lab and see by yourself how simply Camel resolves a typical use case and how easy it is to test, containerize, and run applications in OpenShift.&lt;/p&gt; &lt;p&gt;Camel K is a convenient way to build and deploy integrations with Apache Camel. Its simplicity and ease of use accelerate developers. You might, however, find other Camel runtimes better suited for more advanced use cases. We encourage you to check out the resources below to learn more about Camel K and explore different ways you can build applications with Apache Camel:&lt;/p&gt; &lt;ul&gt;&lt;li aria-level="1"&gt;Play with more &lt;a href="https://developers.redhat.com/articles/2023/03/09/accelerate-your-cloud-native-learning-access-red-hat-developer-sandbox"&gt;tutorials in the Developer Sandbox for Red Hat OpenShift&lt;/a&gt;.&lt;/li&gt; &lt;li aria-level="1"&gt;A good place to start learning about Camel K is the &lt;a href="https://developers.redhat.com/topics/camel-k"&gt;Camel K topic page&lt;/a&gt; on Red Hat Developer.&lt;/li&gt; &lt;li aria-level="1"&gt;Learn how to implement a complete API integration using &lt;a href="https://developers.redhat.com/articles/2021/11/24/normalize-web-services-camel-k-and-atlasmap-part-1"&gt;Camel K and AtlasMap&lt;/a&gt;.&lt;/li&gt; &lt;li aria-level="1"&gt;Learn more about the different Camel runtimes available by reading &lt;a href="https://developers.redhat.com/articles/2022/03/14/choose-best-camel-your-integration-ride-part-1"&gt;Choose the best Camel for your integration ride&lt;/a&gt;.&lt;/li&gt; &lt;li aria-level="1"&gt;Read &lt;a href="https://developers.redhat.com/articles/2021/12/06/boost-apache-camel-performance-quarkus"&gt;Boost Apache Camel performance with Quarkus&lt;/a&gt; for a detailed look at Camel Quarkus.&lt;/li&gt; &lt;li aria-level="1"&gt;Visit the &lt;a href="https://developers.redhat.com/products/integration/overview"&gt;Red Hat Integration&lt;/a&gt; page on developers.redhat.com to see complementary capabilities around Camel.&lt;/li&gt; &lt;/ul&gt; The post &lt;a href="https://developers.redhat.com/articles/2023/03/30/try-camel-k-developer-sandbox-red-hat-openshift" title="Try Camel K in the Developer Sandbox for Red Hat OpenShift"&gt;Try Camel K in the Developer Sandbox for Red Hat OpenShift&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Bruno Meseguer</dc:creator><dc:date>2023-03-30T07:01:00Z</dc:date></entry><entry><title>How to access the Developer Sandbox for Red Hat OpenShift</title><link rel="alternate" href="https://developers.redhat.com/articles/2023/03/30/how-access-developer-sandbox-red-hat-openshift" /><author><name>Bruno Meseguer</name></author><id>b582eb5d-7821-4b58-b5ad-b10477247ebe</id><updated>2023-03-30T07:00:00Z</updated><published>2023-03-30T07:00:00Z</published><summary type="html">&lt;p&gt;Red Hat Developer has many labs that you can easily access through your web browser. The &lt;a href="https://developers.redhat.com/developer-sandbox"&gt;Developer Sandbox for Red Hat OpenShift&lt;/a&gt; lets you experiment with building and deploying cloud-native applications in a real &lt;a href="https://developers.redhat.com/products/openshift/overview"&gt;OpenShift&lt;/a&gt; environment using only your web browser.&lt;/p&gt; &lt;p&gt;With an integrated development environment (IDE) called &lt;a href="https://developers.redhat.com/products/openshift-dev-spaces/overview"&gt;Red Hat OpenShift Dev Spaces&lt;/a&gt; (formerly Red Hat CodeReady Workspaces), the Developer Sandbox is a playground for developers looking to explore &lt;a href="https://developers.redhat.com/topics/kubernetes/"&gt;Kubernetes&lt;/a&gt;-based application platforms. This article provides a step-by-step guide to getting started with the Developer Sandbox, where you can, for example, dive into the process of creating a Camel integration through a web-based interface.&lt;/p&gt; &lt;p&gt;The best part? No local installs are required, making it easier than ever to get started. The steps in this article will guide you through how to set up your own free-to-use environment.&lt;/p&gt; &lt;h2&gt;Access the Developer Sandbox for Red Hat OpenShift&lt;/h2&gt; &lt;ol&gt;&lt;li aria-level="1"&gt;Navigate to the &lt;a href="https://developers.redhat.com/developer-sandbox" target="_blank"&gt;Developer Sandbox&lt;/a&gt;.&lt;/li&gt; &lt;li aria-level="1"&gt; &lt;p&gt;Click the red button labeled &lt;strong&gt;Start your sandbox for free&lt;/strong&gt; (Figure 1).&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;img alt="Open developer sandbox" data-entity-type="file" data-entity-uuid="2b964245-2020-4e97-be20-0fa131cb5944" height="201" src="https://developers.redhat.com/sites/default/files/inline-images/01-try-devsandbox-comp.jpeg" width="577" loading="lazy" /&gt;&lt;figcaption class="rhd-c-caption"&gt;Figure 1: Start your sandbox for free.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/li&gt; &lt;li aria-level="1"&gt; &lt;p&gt;You will then be prompted to log in with your Red Hat account (Figure 2). If you don't have an existing account, click &lt;strong&gt;Register for a Red Hat account&lt;/strong&gt;. Complete the registration process to create an account and then return to this step.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;img alt="The Developer Sandbox for Red Hat OpenShift login screen." data-entity-type=" file" data-entity-uuid="21d68975-5b2a-4f7a-9365-b4c266579238" height="214" src="https://developers.redhat.com/sites/default/files/inline-images/02-register-redhat-account-comp.jpeg" width="274" /&gt;&lt;figcaption class="rhd-c-caption"&gt;Figure 2: Log in with your Red Hat account.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/li&gt; &lt;li aria-level="1"&gt; &lt;p&gt;You should see a screen, as shown in Figure 3. Click the red button: &lt;strong&gt;Start using your sandbox&lt;/strong&gt;. This will take you to the Red Hat OpenShift Dedicated login page.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;img alt="Start using Sandbox" data-entity-type="file" data-entity-uuid="3a7fcbfb-7b8a-4d9e-97b3-b26eddf74522" height="266" src="https://developers.redhat.com/sites/default/files/inline-images/04-start-using-sandbox-comp.jpeg" width="568" loading="lazy" /&gt;&lt;figcaption class="rhd-c-caption"&gt;Figure 3: Start using the Sandbox.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/li&gt; &lt;li aria-level="1"&gt; &lt;p&gt;Click the &lt;strong&gt;DevSandbox&lt;/strong&gt; button from this screen (Figure 4).&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;img alt="Login with Dev sandbox" data-entity-type="file" data-entity-uuid="07bdd516-1067-4293-acba-213962ff7e18" height="152" src="https://developers.redhat.com/sites/default/files/inline-images/05-login-sandbox-comp.jpeg" width="562" loading="lazy" /&gt;&lt;figcaption class="rhd-c-caption"&gt;Figure 4: Log in with Dev Sandbox&lt;/figcaption&gt;&lt;/figure&gt;&lt;/li&gt; &lt;li aria-level="1"&gt; &lt;p&gt;The environment will welcome you with the message shown in Figure 5.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;img alt="Developer Sandbox Welcome" data-entity-type="file" data-entity-uuid="ead9f98c-7d71-44c8-8f46-3e1aceee1499" height="176" src="https://developers.redhat.com/sites/default/files/inline-images/07-welcome-developer-comp.jpeg" width="488" loading="lazy" /&gt;&lt;figcaption class="rhd-c-caption"&gt;Figure 5: Welcome to the Developer Perspective&lt;/figcaption&gt;&lt;/figure&gt;&lt;/li&gt; &lt;/ol&gt;&lt;p&gt;You have now entered the Developer Sandbox!&lt;/p&gt; &lt;h2&gt;Activities to learn Camel and Camel K&lt;/h2&gt; &lt;p&gt;For developers looking to get started with Camel and Camel K, here are two step-by-step guides you can try:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2023/03/09/try-camel-k-developer-sandbox"&gt;Try Camel K in the Developer Sandbox for Red Hat OpenShift&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2023/02/10/how-run-camel-spring-boot-red-hat-developer-sandbox"&gt;How to run Camel on Spring Boot in the Developer Sandbox&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; The post &lt;a href="https://developers.redhat.com/articles/2023/03/30/how-access-developer-sandbox-red-hat-openshift" title="How to access the Developer Sandbox for Red Hat OpenShift"&gt;How to access the Developer Sandbox for Red Hat OpenShift&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Bruno Meseguer</dc:creator><dc:date>2023-03-30T07:00:00Z</dc:date></entry><entry><title>Quarkus 3.0.0.CR1 released</title><link rel="alternate" href="&#xA;                https://quarkus.io/blog/quarkus-3-0-0-cr1-released/&#xA;            " /><author><name>Guillaume Smet (https://twitter.com/gsmet_)</name></author><id>https://quarkus.io/blog/quarkus-3-0-0-cr1-released/</id><updated>2023-03-30T00:00:00Z</updated><published>2023-03-30T00:00:00Z</published><summary type="html">It is our pleasure to announce the availability of Quarkus 3.0.0.CR1. We are working full steam on polishing Quarkus 3.0 so please try it with your applications and report any problem to us by creating a GitHub issue. To upgrade your application to Quarkus 3.0, see the instructions below. Among...</summary><dc:creator>Guillaume Smet (https://twitter.com/gsmet_)</dc:creator><dc:date>2023-03-30T00:00:00Z</dc:date></entry><entry><title>The developer's guide to Red Hat Summit 2023</title><link rel="alternate" href="https://developers.redhat.com/articles/2023/03/29/developers-guide-red-hat-summit-2023" /><author><name>Colleen Lobner</name></author><id>09e73bae-a9db-4655-98fc-0f1418d315b8</id><updated>2023-03-29T14:00:00Z</updated><published>2023-03-29T14:00:00Z</published><summary type="html">&lt;p&gt;The wait is over: The session catalog and agenda builder are now available for &lt;a href="https://www.redhat.com/en/summit"&gt;Red Hat Summit 2023&lt;/a&gt;, which kicks off May 23 in Boston, Massachusetts. This year, Summit will share the stage with AnsibleFest, bringing you the latest in &lt;a href="https://developers.redhat.com/topics/automation"&gt;automation&lt;/a&gt;, open hybrid cloud, and more, all in one place.&lt;/p&gt; &lt;p&gt;We’re also offering a virtual option so attendees can get the most out of their 3-day conference experience. Pre-register at no cost to view keynotes and select on-site sessions to watch at your own pace after the event concludes.&lt;/p&gt; &lt;p&gt;We’ve rounded up some of the highlights for developers to help you plan your agenda. Head over to the Red Hat Summit website to &lt;a href="https://events.experiences.redhat.com/widget/redhat/sum23/SessionCatalog2023?tab.day=20230522"&gt;browse the full session catalog&lt;/a&gt; and &lt;a href="https://reg.experiences.redhat.com/flow/redhat/sum23/regGenAttendee/login?intcmp=7013a000003DMkYAAW"&gt;register today&lt;/a&gt;! &lt;/p&gt; &lt;h2&gt;Why attend Red Hat Summit?&lt;/h2&gt; &lt;p&gt;Here’s what Red Hat Summit has to offer:&lt;/p&gt; &lt;ul&gt;&lt;li aria-level="1"&gt;&lt;strong&gt;Engage in hands-on learning opportunities.&lt;/strong&gt; Get started with a new tool and develop in-demand skills. Stop by the Red Hat Developer booth to explore what’s possible in the &lt;a href="https://developers.redhat.com/developer-sandbox"&gt;Developer Sandbox for Red Hat OpenShift&lt;/a&gt;.&lt;/li&gt; &lt;li aria-level="1"&gt;&lt;strong&gt;Find out how industry leaders are tackling today’s biggest challenges.&lt;/strong&gt; Get insights and learn from tech experts, Red Hat customers and partners, and community members via keynotes, interactive sessions, and networking.&lt;/li&gt; &lt;li aria-level="1"&gt;&lt;strong&gt;Collaborate, network, and discover the latest Red Hat technologies.&lt;/strong&gt; You’ll walk away brimming with fresh ideas and inspiration to advance your projects, organization, and career.&lt;/li&gt; &lt;/ul&gt;&lt;h2&gt;Dive into developer experience&lt;/h2&gt; &lt;p&gt;If you’re passionate about good developer experience, here are a few workshops and interactive sessions we think you’ll love.&lt;/p&gt; &lt;h3&gt;Red Hat Developer Tools overview and roadmap&lt;/h3&gt; &lt;p&gt;This session explores how Red Hat supports a cloud-first approach to cloud-native development and how it relates to the multicloud and hybrid cloud challenges developers face today. &lt;/p&gt; &lt;p&gt;Red Hat Developer’s &lt;a href="https://developers.redhat.com/author/mithun-t-dhar/"&gt;Mithun Dhar&lt;/a&gt;, &lt;a href="https://developers.redhat.com/author/parag-dave"&gt;Parag Dave&lt;/a&gt;, and &lt;a href="https://developers.redhat.com/author/mohit-suman/"&gt;Mohit Suman&lt;/a&gt; will illustrate how Red Hat's &lt;a href="https://developers.redhat.com/topics/developer-tools"&gt;developer tools&lt;/a&gt; remove friction and help teams ship applications and deliver value in less time and for less cost. They’ll cover:&lt;/p&gt; &lt;ul&gt;&lt;li aria-level="1"&gt;The full life cycle of the development process, from creating a new application, iterating it, and supporting a security-focused software delivery pipeline.&lt;/li&gt; &lt;li aria-level="1"&gt;Developer productivity with &lt;a href="https://developers.redhat.com/topics/containers"&gt;containers&lt;/a&gt;, &lt;a href="https://developers.redhat.com/topics/kubernetes/"&gt;Kubernetes&lt;/a&gt;, and &lt;a href="https://developers.redhat.com/products/openshift/overview"&gt;Red Hat OpenShift&lt;/a&gt;.&lt;/li&gt; &lt;li aria-level="1"&gt;Tools that meet developers where they are: &lt;a href="https://developers.redhat.com/products/openshift-ide-extensions/overview"&gt;integrated development environments&lt;/a&gt; (e.g., VS Code, IntelliJ, hosted), command-line interfaces (CLI), web UIs, and more.&lt;/li&gt; &lt;li aria-level="1"&gt;Hosted offerings that provide a frictionless experience for developers to experiment and iterate over their cloud-native applications.&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;&lt;a href="https://events.experiences.redhat.com/widget/redhat/sum23/SessionCatalog2023/session/1672958649092001ePts?intcmp=7013a000003DMkYAAW"&gt;&lt;strong&gt;See full session details.&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; &lt;h3&gt;The internal developer platform: Scaffolding for cloud-native development&lt;/h3&gt; &lt;p&gt;The Red Hat Developer team is excited to host a hands-on workshop focused on the internal developer platform (IDP) on Tuesday, May 23, from 6-8 pm ET. In this hands-on session led by Red Hat’s &lt;a href="https://developers.redhat.com/authors/ryan-jarvinen/"&gt;Ryan Jarvinen&lt;/a&gt;, attendees will explore how &lt;a href="https://developers.redhat.com/articles/2022/10/24/red-hat-joins-backstageio-community"&gt;Backstage&lt;/a&gt; encapsulates tools, services, documentation, and best practices in “golden paths” to ease onboarding and daily development work.&lt;/p&gt; &lt;p&gt;Each participant will build and deploy a 3-tier web application using headline Red Hat products and technologies. You will see how these tools work together to support daily development activities and construct flexible foundations for cloud-native development. &lt;/p&gt; &lt;ul&gt;&lt;li aria-level="1"&gt;Discover how Backstage tools help you mount your team’s scaffolding and apply best practices atop.&lt;/li&gt; &lt;li aria-level="1"&gt;View and change source code in &lt;a href="https://developers.redhat.com/products/openshift-dev-spaces/overview"&gt;Red Hat OpenShift Dev Spaces&lt;/a&gt;, a web-based integrated development environment built on VS Code.&lt;/li&gt; &lt;li aria-level="1"&gt;Automate the build-test-deploy cycle using &lt;a href="https://developers.redhat.com/topics/gitops"&gt;GitOps&lt;/a&gt; and build-test pipeline modules as you iterate your application with new features and fixes.&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;&lt;a href="https://events.experiences.redhat.com/widget/redhat/sum23/SessionCatalog2023/session/1679078902891001Yxy9?intcmp=7013a000003DMkYAAW"&gt;&lt;strong&gt;See full session details.&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; &lt;h3&gt;Shaping the future of the IDPs using Backstage&lt;/h3&gt; &lt;p&gt;Developers deserve great experiences, too! A developer portal can decrease the cognitive load for developers and provide solutions that help onboard developers as well as applications, resulting in faster delivery for less money. &lt;/p&gt; &lt;p&gt;In this session, Red Hat’s &lt;a href="https://developers.redhat.com/author/serena-chechile-nichols"&gt;Serena Chechile&lt;/a&gt; will demonstrate how Red Hat supports an internal developer platform (IDP) that solves challenges that developers face today while increasing engineering productivity. You’ll also learn about our developer productivity bundle for Backstage. &lt;/p&gt; &lt;p&gt;&lt;a href="https://events.experiences.redhat.com/widget/redhat/sum23/SessionCatalog2023/session/1677711290856001s4aC?intcmp=7013a000003DMkYAAW"&gt;&lt;strong&gt;See full session details.&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; &lt;h3&gt;Supercharge your developer portal with Red Hat integrations&lt;/h3&gt; &lt;p&gt;Explore tools that help lower the barrier of entry for getting started with Backstage, providing a richer software catalog through a variety of plug-ins and integrations. In this session, Red Hat’s &lt;a href="https://developers.redhat.com/author/andrew-block/"&gt;Andrew Block&lt;/a&gt; and Tom Coufal will introduce these extension points to the Backstage ecosystem that provide integrations into various Red Hat offerings, starting with Red Hat’s single sign-on technology, Red Hat Quay, and Red Hat Advanced Cluster Management for Kubernetes. &lt;/p&gt; &lt;p&gt;&lt;a href="https://events.experiences.redhat.com/widget/redhat/sum23/SessionCatalog2023/session/1673460487820001sB3k?intcmp=7013a000003DMkYAAW"&gt;&lt;strong&gt;See full session details.&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; &lt;h3&gt;Dev Spaces on ROSA: Enabling developers in a regulated enterprise environment &lt;/h3&gt; &lt;p&gt;A major UK bank needed a developer environment that could start up quickly, meet security standards for source code, integrate with different developer tooling, and serve a developer population at scale. They decided to spin up &lt;a href="https://developers.redhat.com/products/openshift-dev-spaces/overview"&gt;Red Hat OpenShift Dev Spaces&lt;/a&gt; on Red Hat OpenShift Service on AWS (ROSA).&lt;/p&gt; &lt;p&gt;In this session, NatWest Group’s Baljinder Kang and Red Hat’s &lt;a href="https://developers.redhat.com/author/anton-giertli/"&gt;Anton Giertli&lt;/a&gt; will explain how they used OpenShift Dev Spaces on ROSA and integrated developer tooling. This session will be useful for organizations that want to streamline their developer journeys while keeping the administration loads to a minimum.&lt;/p&gt; &lt;p&gt;&lt;a href="https://events.experiences.redhat.com/widget/redhat/sum23/SessionCatalog2023/session/1673455911314001CJJi?intcmp=7013a000003DMkYAAW"&gt;&lt;strong&gt;See full session details.&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; &lt;p class="Indent2"&gt;&lt;strong&gt;&lt;em&gt;[ Learning path: &lt;a href="https://developers.redhat.com/node/279091"&gt;How to deploy an application using Red Hat OpenShift Service on AWS&lt;/a&gt; ]&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt; &lt;h3&gt;Investing in developer experience at Delta Air Lines to fly higher and faster&lt;/h3&gt; &lt;p&gt;This session will examine how Delta Air Lines uses Red Hat technologies to create a better developer experience with a platform that meets strict internal requirements and the needs of a demanding industry, while still providing the autonomy that enables developers to be their most effective.&lt;/p&gt; &lt;p&gt;Red Hat’s Prakriti Koller, Eric Sauer, and Delta’s Brittany Doncaster will share:&lt;/p&gt; &lt;ul&gt;&lt;li aria-level="1"&gt;How they went about selecting measures that focused on people and business outcomes and committed to transparency along the way&lt;/li&gt; &lt;li aria-level="1"&gt;How using OpenShift Dev Spaces helped improve Delta’s speed to market&lt;/li&gt; &lt;li aria-level="1"&gt;Which working practices showed results&lt;/li&gt; &lt;li aria-level="1"&gt;What they learned while trying to collect and automate measurement&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;&lt;a href="https://events.experiences.redhat.com/widget/redhat/sum23/SessionCatalog2023/session/1673483793804001yZt2?intcmp=7013a000003DMkYAAW"&gt;&lt;strong&gt;See full session details.&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; &lt;h2&gt;More hands-on labs and workshops&lt;/h2&gt; &lt;p&gt;These sessions dive into GitOps, Kubernetes automation, &lt;a href="https://developers.redhat.com/products/quarkus/overview"&gt;Quarkus&lt;/a&gt;, and other topics to help you stay ahead of the curve.&lt;/p&gt; &lt;h3&gt;Using GitOps to control and customize your OpenShift clusters and applications&lt;/h3&gt; &lt;p&gt;Based on the Argo CD project, Red Hat OpenShift GitOps enables organizations to implement GitOps-based &lt;a href="http://developers.redhat.com/topics/ci-cd"&gt;continuous delivery (CD)&lt;/a&gt; workflows to manage their OpenShift Container Platform instances and applications across multi-cluster Kubernetes environments. &lt;/p&gt; &lt;p&gt;In this session, you will explore the benefits of GitOps and where to begin your GitOps adoption journey. Red Hat’s &lt;a href="https://developers.redhat.com/author/evan-shortiss/"&gt;Evan Shortiss&lt;/a&gt;, &lt;a href="https://developers.redhat.com/author/natale-vinto/"&gt;Natale Vinto&lt;/a&gt; (co-author of the new &lt;a href="https://developers.redhat.com/e-books/gitops-cookbook"&gt;GitOps Cookbook&lt;/a&gt;), and &lt;a href="https://developers.redhat.com/authors/ryan-jarvinen/"&gt;Ryan Jarvinen&lt;/a&gt; will demonstrate how to use OpenShift GitOps to customize and manage an OpenShift cluster. Attendees will also learn how to deploy and manage applications using Red Hat OpenShift GitOps, and how it can detect and auto-correct configuration drift between the desired configuration stored in a Git repository and the actual state on their OpenShift cluster. &lt;/p&gt; &lt;p&gt;&lt;a href="https://events.experiences.redhat.com/widget/redhat/sum23/SessionCatalog2023/session/1673389536296001y1dZ?intcmp=7013a000003DMkYAAW"&gt;&lt;strong&gt;See full session details.&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; &lt;h3&gt;From zero to hero in Kubernetes-native Java&lt;/h3&gt; &lt;p&gt;More than 16.5 million &lt;a href="https://developers.redhat.com/java"&gt;Java&lt;/a&gt; developers are currently working to realize business requirements and spend a ton of time and effort to optimize the application performance for a variety of workloads (e.g., web, mobile, &lt;a href="https://developers.redhat.com/topics/ai-ml"&gt;AI/ML&lt;/a&gt;, &lt;a href="https://developers.redhat.com/topics/edge-computing"&gt;edge&lt;/a&gt;) in the cloud. A big challenge is adopting a new programming language or runtime over Java due to the lack of compatibility with Kubernetes. &lt;/p&gt; &lt;p&gt;In this session, Red Hat’s &lt;a href="https://developers.redhat.com/author/daniel-oh"&gt;Daniel Oh&lt;/a&gt; will walk you through how developers can scaffold a Java project from scratch and then evolve it as a Kubernetes-native application in terms of optimizing resources with the native build, integrating Kubernetes manifest (ConfigMap, Secret, Health Check), building container images, and deploying it to Kubernetes. You can also continue testing and debugging the application while it’s already deployed to the remote Kubernetes, the same as the local developer experiences of inner-loop development.&lt;/p&gt; &lt;p&gt;&lt;a href="https://events.experiences.redhat.com/widget/redhat/sum23/SessionCatalog2023/session/1671448348507001lKXA?intcmp=7013a000003DMkYAAW"&gt;&lt;strong&gt;See full session details.&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; &lt;h3&gt;Vote App: A complete end-to-end story from code to prod&lt;/h3&gt; &lt;p&gt;In this lab, Red Hat’s &lt;a href="https://developers.redhat.com/author/natale-vinto/"&gt;Natale Vinto&lt;/a&gt;, &lt;a href="https://developers.redhat.com/author/cedric-clyburn/"&gt;Cedric Clyburn&lt;/a&gt;, and &lt;a href="https://developers.redhat.com/author/evan-shortiss/"&gt;Evan Shortiss&lt;/a&gt; will walk through a complete development journey example of a 2-tier application made with &lt;a href="https://developers.redhat.com/topics/python"&gt;Python&lt;/a&gt; and &lt;a href="https://developers.redhat.com/topics/go"&gt;Go&lt;/a&gt;, built and deployed on Red Hat OpenShift. &lt;/p&gt; &lt;p&gt;You'll start coding with Red Hat OpenShift Dev Spaces, a modern in-browser IDE, and create container images with OpenShift Pipelines and Quay.io; then, you'll deploy and promote the application into several environments using OpenShift GitOps. This lab will help you get more familiar with cloud-native development, Kubernetes automation, and the GitOps methodology.&lt;/p&gt; &lt;p&gt;&lt;a href="https://events.experiences.redhat.com/widget/redhat/sum23/SessionCatalog2023/session/1673448136004001vsNU?intcmp=7013a000003DMkYAAW"&gt;&lt;strong&gt;See full session details.&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; &lt;h3&gt;Enter Serverless Functions journey with Quarkus&lt;/h3&gt; &lt;p&gt;In this hands-on workshop, Red Hat’s &lt;a href="https://developers.redhat.com/author/daniel-oh"&gt;Daniel Oh&lt;/a&gt; walks through how to scaffold a &lt;a href="https://developers.redhat.com/topics/serverless-architecture/"&gt;serverless&lt;/a&gt; functions project using Quarkus, a Kubernetes-native Java framework. He will cover how to deploy service functions to AWS Lambda, optimize the functions, and make them portable across multiple serverless platforms (e.g., AWS Lambda, Azure Functions, Google Cloud Platform, Kubernetes Knative). You’ll also use handy command-line tools like &lt;code&gt;kn func&lt;/code&gt; to enable a Buildpack for function development &amp; deployment in minutes. &lt;/p&gt; &lt;p&gt;Lab participants will be provided a free sandbox for serverless deployments. You’ll learn how to quickly create cloud-native microservice projects using Quarkus. Then, you’ll deploy the application to a function to AWS Lambda and Knative Event with JVM and Native mode.&lt;/p&gt; &lt;p&gt;&lt;a href="https://events.experiences.redhat.com/widget/redhat/sum23/SessionCatalog2023/session/1671448706376001mamw?intcmp=7013a000003DMkYAAW"&gt;&lt;strong&gt;See full session details.&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Note: &lt;/strong&gt;Be sure to check back as more sessions are added here! In the meantime, you can &lt;a href="https://events.experiences.redhat.com/widget/redhat/sum23/SessionCatalog2023?tab.day=20230522"&gt;browse the full session catalog&lt;/a&gt; and &lt;a href="https://reg.experiences.redhat.com/flow/redhat/sum23/regGenAttendee/login?intcmp=7013a000003DMkYAAW"&gt;register now&lt;/a&gt; at the Red Hat Summit website. &lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2023/03/29/developers-guide-red-hat-summit-2023" title="The developer's guide to Red Hat Summit 2023"&gt;The developer's guide to Red Hat Summit 2023&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Colleen Lobner</dc:creator><dc:date>2023-03-29T14:00:00Z</dc:date></entry></feed>
